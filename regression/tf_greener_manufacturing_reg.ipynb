{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1fa078-0c74-4bff-8c35-a12bcf9e0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81bbeee-4273-48ce-8585-da66f9cd5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a553ace-fdc7-410a-92bd-0649cfcb136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4209"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"dataset/regression/mercedes-benz-greener-manufacturing/train.csv\")\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a565065e-f871-4787-9b0d-a57d6e16301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421236b1-250b-4ce3-912f-7e04f6788425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"X0\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8035fd72-e55a-49ef-b330-3b7b5d47c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      0\n",
       "y       0\n",
       "X0      0\n",
       "X1      0\n",
       "X2      0\n",
       "       ..\n",
       "X380    0\n",
       "X382    0\n",
       "X383    0\n",
       "X384    0\n",
       "X385    0\n",
       "Length: 378, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7cbdd49-78a7-4b8c-b159-09fb3c0e8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4209 entries, 0 to 4208\n",
      "Columns: 378 entries, ID to X385\n",
      "dtypes: float64(1), int64(369), object(8)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16c3edcb-1f32-4fa0-ba70-e008384bc207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['k', 'az', 't', 'al', 'o', 'w', 'j', 'h', 's', 'n', 'ay', 'f', 'x',\n",
       "       'y', 'aj', 'ak', 'am', 'z', 'q', 'at', 'ap', 'v', 'af', 'a', 'e',\n",
       "       'ai', 'd', 'aq', 'c', 'aa', 'ba', 'as', 'i', 'r', 'b', 'ax', 'bc',\n",
       "       'u', 'ad', 'au', 'm', 'l', 'aw', 'ao', 'ac', 'g', 'ab'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.X0.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34e71b7-2841-4415-b106-c9d51db1e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "for label, content in train_data.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        cat_dict[label] = sorted(train_data[label].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9694a4ce-a071-4256-9183-f9ef43741f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'ac',\n",
       " 'ad',\n",
       " 'af',\n",
       " 'ai',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'am',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'aq',\n",
       " 'as',\n",
       " 'at',\n",
       " 'au',\n",
       " 'aw',\n",
       " 'ax',\n",
       " 'ay',\n",
       " 'az',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'bc',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict.get(\"X0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6756d93d-4c37-4b34-8058-02859a910789",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in train_data.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        train_data[label] = content.astype(\"category\")\n",
    "        train_data[label] = pd.Categorical(content, categories=cat_dict.get(label)).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32483fa2-cfd5-4d89-89a2-5df449a00685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0  X1  X2  X3  X4  X5  X6  X8  ...  X375  X376  X377  X378  \\\n",
       "0   0  130.81  33  24  18   1   4  25  10  15  ...     0     0     1     0   \n",
       "1   6   88.53  33  22  20   5   4  29  12  15  ...     1     0     0     0   \n",
       "2   7   76.26  21  25  35   3   4  28  10  24  ...     0     0     0     0   \n",
       "3   9   80.62  21  22  35   6   4  28  12   5  ...     0     0     0     0   \n",
       "4  13   78.02  21  24  35   6   4  13   4  14  ...     0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1499441-3847-483d-a426-01592a73a965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, y, X0, X1, X2, X3, X4, X5, X6, X8, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21, X22, X23, X24, X26, X27, X28, X29, X30, X31, X32, X33, X34, X35, X36, X37, X38, X39, X40, X41, X42, X43, X44, X45, X46, X47, X48, X49, X50, X51, X52, X53, X54, X55, X56, X57, X58, X59, X60, X61, X62, X63, X64, X65, X66, X67, X68, X69, X70, X71, X73, X74, X75, X76, X77, X78, X79, X80, X81, X82, X83, X84, X85, X86, X87, X88, X89, X90, X91, X92, X93, X94, X95, X96, X97, X98, X99, X100, X101, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 378 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.X0 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeea4e43-abfa-4cef-a2a2-ce1374b8142a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...  X375  X376  X377  X378  X379  X380  \\\n",
       "0   1  az  v   n  f  d  t  a  w    0  ...     0     0     0     1     0     0   \n",
       "1   2   t  b  ai  a  d  b  g  y    0  ...     0     0     1     0     0     0   \n",
       "2   3  az  v  as  f  d  a  j  j    0  ...     0     0     0     1     0     0   \n",
       "3   4  az  l   n  f  d  z  l  n    0  ...     0     0     0     1     0     0   \n",
       "4   5   w  s  as  c  d  y  i  m    0  ...     1     0     0     0     0     0   \n",
       "\n",
       "   X382  X383  X384  X385  \n",
       "0     0     0     0     0  \n",
       "1     0     0     0     0  \n",
       "2     0     0     0     0  \n",
       "3     0     0     0     0  \n",
       "4     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"dataset/regression/mercedes-benz-greener-manufacturing/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bcec4d2-829a-4a17-98b1-71eb8fc8f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in test_data.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        test_data[label] = content.astype(\"category\")\n",
    "        test_data[label] = pd.Categorical(content, categories=cat_dict.get(label)).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87f68c2f-e4d7-481e-aa0a-3b17245ce0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...  X375  X376  X377  X378  X379  \\\n",
       "0   1  21  24  35   6   4   0   1  23    0  ...     0     0     0     1     0   \n",
       "1   2  41   4   8   1   4   0   7  25    0  ...     0     0     1     0     0   \n",
       "2   3  21  24  17   6   4   0  10  10    0  ...     0     0     0     1     0   \n",
       "3   4  21  14  35   6   4   0  12  14    0  ...     0     0     0     1     0   \n",
       "4   5  44  21  17   3   4  29   9  13    0  ...     1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a486e76-4cd0-40ce-8d67-18f6c2f96d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>5816</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>6585</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>7420</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>7805</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...  X375  X376  X377  X378  \\\n",
       "153    289   0   5   3   3   4  15   7   6    0  ...     0     0     1     0   \n",
       "311    624   0  14  17   6   4  14  10  21    0  ...     0     0     0     0   \n",
       "2914  5816   0   5   3   3   4  21   5  23    0  ...     0     0     1     0   \n",
       "3281  6585   0   4   3   3   4  22  10   5    0  ...     0     0     1     0   \n",
       "3718  7420   0  24  17   1   4  26   1   7    0  ...     0     0     1     0   \n",
       "3913  7805   0  22  20   6   4  27   1   7    0  ...     0     0     0     0   \n",
       "\n",
       "      X379  X380  X382  X383  X384  X385  \n",
       "153      0     0     0     0     0     0  \n",
       "311      0     0     0     0     0     0  \n",
       "2914     0     0     0     0     0     0  \n",
       "3281     0     0     0     0     0     0  \n",
       "3718     0     0     0     0     0     0  \n",
       "3913     0     0     0     0     0     0  \n",
       "\n",
       "[6 rows x 377 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data.X0 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5a1d27-d4a8-4a74-9bf3-e836694b86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(0.8 * len(train_data))\n",
    "train_features, train_target = train_data.drop([\"ID\", \"y\"], axis = 1).to_numpy()[:split_size], train_data[\"y\"].to_numpy()[:split_size]\n",
    "val_features, val_target = train_data.drop([\"ID\", \"y\"], axis = 1).to_numpy()[split_size:], train_data[\"y\"].to_numpy()[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a83f51-6fa9-49ae-882c-ef5331e4a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 3367, 842, 842)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features), len(train_target), len(val_features), len(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db3c5b67-b0dc-4bc0-8397-993095a7c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 24, 18, ...,  0,  0,  0],\n",
       "       [33, 22, 20, ...,  0,  0,  0],\n",
       "       [21, 25, 35, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [28,  5, 34, ...,  0,  0,  0],\n",
       "       [45, 20, 21, ...,  0,  0,  0],\n",
       "       [40,  4,  4, ...,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6639646-9ea9-4c62-b7a9-fff1c2b3e183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130.81,  88.53,  76.26, ...,  91.46, 108.76, 118.93])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f67490-9849-43f9-ae4f-b40192a9f029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba37edd6-a663-4e25-9a98-c4ab83ccc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performant datasets\n",
    "train_features_1 = tf.data.Dataset.from_tensor_slices(tf.cast(train_features, dtype=tf.float32))\n",
    "train_target_1 = tf.data.Dataset.from_tensor_slices(tf.cast(train_target, dtype=tf.float32))\n",
    "train_dataset_1 = tf.data.Dataset.zip((train_features_1, train_target_1)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_features_1 = tf.data.Dataset.from_tensor_slices(tf.cast(val_features, dtype=tf.float32))\n",
    "val_target_1 = tf.data.Dataset.from_tensor_slices(tf.cast(val_target, dtype=tf.float32))\n",
    "val_dataset_1 = tf.data.Dataset.zip((val_features_1, val_target_1)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dc607ab0-732a-4d7d-88c5-0470b7b54a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "CHECKPOINT_PATH = \"model_experiments/greener_manufacturing\"\n",
    "LOGS_PATH = \"model_logs/greener_manufacturing\"\n",
    "\n",
    "def checkpoint(model_name):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_PATH, model_name), \n",
    "                                              save_best_only=True, \n",
    "                                              monitor=\"val_loss\")\n",
    "\n",
    "def tensorboard(model_name):\n",
    "    return tf.keras.callbacks.TensorBoard(os.path.join(LOGS_PATH, model_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.1, min_lr=1e-5, verbose=1)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (epoch/10), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f0497f-69df-4f0e-ab46-765fb2ec4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(376,), dtype=tf.float32)\n",
    "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1\")\n",
    "\n",
    "model_1.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9b13628-5b04-4e90-8eaa-026dee800313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 376)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               48256     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,897\n",
      "Trainable params: 64,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c08a77c7-1bcf-49f5-8bd9-55f12ade28ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "103/106 [============================>.] - ETA: 0s - loss: 28.4391INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 10s 28ms/step - loss: 28.0024 - val_loss: 8.7729 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - ETA: 0s - loss: 8.5300INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 16ms/step - loss: 8.5300 - val_loss: 8.0378 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "103/106 [============================>.] - ETA: 0s - loss: 8.0096INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 7.9659 - val_loss: 7.8492 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - ETA: 0s - loss: 7.7715INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 7.7715 - val_loss: 7.7905 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "105/106 [============================>.] - ETA: 0s - loss: 6.9593INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 18ms/step - loss: 6.9593 - val_loss: 7.3891 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "105/106 [============================>.] - ETA: 0s - loss: 6.6401INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 16ms/step - loss: 6.6400 - val_loss: 7.1448 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 6.5379INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 17ms/step - loss: 6.4633 - val_loss: 7.0667 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "101/106 [===========================>..] - ETA: 0s - loss: 6.4519INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 15ms/step - loss: 6.3944 - val_loss: 6.9648 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - ETA: 0s - loss: 6.2943INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 1s 14ms/step - loss: 6.2943 - val_loss: 6.9554 - lr: 0.0010\n",
      "Epoch 10/10\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 6.0747INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_1\\assets\n",
      "106/106 [==============================] - 2s 18ms/step - loss: 6.0295 - val_loss: 6.8882 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=10,\n",
    "                              steps_per_epoch=len(train_dataset_1),\n",
    "                              validation_steps=len(val_dataset_1),\n",
    "                              callbacks=[tensorboard(model_1.name),\n",
    "                                         checkpoint(model_1.name),\n",
    "                                         early_stopping,\n",
    "                                         reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f798a26a-7248-449d-880f-c80c90e1de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f60975c0-5f1e-4850-a614-ea134caeabfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(842,), dtype=float32, numpy=\n",
       "array([108.26427 ,  90.18392 , 109.08108 ,  92.66478 , 106.99931 ,\n",
       "        91.10764 ,  87.19774 , 111.068   ,  90.52078 , 103.559944,\n",
       "       100.81326 ,  92.52583 , 110.83441 , 110.58621 ,  92.261024,\n",
       "        95.82588 , 108.04601 , 109.09022 ,  77.69963 ,  98.13727 ,\n",
       "        97.10927 ,  91.226654, 110.71694 ,  92.65742 ,  88.02055 ,\n",
       "       100.51894 , 112.85677 ,  91.7881  , 105.903336,  94.6952  ,\n",
       "       107.329704, 105.35341 ,  95.71992 , 106.92418 , 102.17631 ,\n",
       "        94.017204, 108.81328 ,  91.88544 ,  93.96883 ,  75.88628 ,\n",
       "        90.62642 ,  91.295975, 110.05093 ,  92.871216,  94.48992 ,\n",
       "        93.88432 , 100.34436 ,  94.69303 ,  94.60633 , 103.03981 ,\n",
       "       108.287384,  77.6352  ,  85.77764 ,  92.414406, 106.623825,\n",
       "       109.25921 ,  91.051315,  94.82184 , 107.64351 , 109.58798 ,\n",
       "        95.70739 , 107.33075 , 106.45076 ,  93.042755, 100.90798 ,\n",
       "        91.26719 ,  93.70541 , 106.59866 ,  89.37452 , 107.04807 ,\n",
       "       103.68874 ,  90.231735,  91.07368 ,  91.21654 , 112.02098 ,\n",
       "        90.70148 ,  88.24596 , 106.88643 , 103.96546 ,  75.35115 ,\n",
       "       107.242805, 109.71423 ,  93.47625 , 107.42282 , 100.257805,\n",
       "        95.5663  , 108.29602 ,  92.818085,  99.26721 ,  94.55333 ,\n",
       "       112.03391 ,  92.66115 ,  77.61498 , 104.41724 ,  96.97724 ,\n",
       "       110.133   , 104.87741 ,  91.148254,  96.78498 , 105.64609 ,\n",
       "        89.74652 , 102.77676 ,  75.721245, 104.87741 ,  92.897385,\n",
       "       102.22006 , 105.73178 ,  91.66903 ,  99.281075, 110.23765 ,\n",
       "        91.91645 ,  92.94266 ,  93.07139 ,  91.86646 ,  93.82444 ,\n",
       "        88.08017 ,  94.13243 , 108.76279 ,  92.380196,  75.64625 ,\n",
       "        92.59944 , 110.671745,  90.857765, 111.983734, 108.86987 ,\n",
       "       101.8299  ,  94.561134,  85.77764 , 111.225746,  92.37213 ,\n",
       "        93.3679  ,  94.69782 ,  77.31472 ,  90.58759 , 104.2576  ,\n",
       "        95.54379 ,  91.81196 ,  91.663376,  92.63592 ,  94.670265,\n",
       "       104.098   ,  90.344215,  94.69782 , 104.44285 ,  97.00316 ,\n",
       "       111.44952 ,  92.37213 ,  94.561134, 108.780174,  93.66984 ,\n",
       "       100.08901 ,  91.16845 , 112.02098 ,  94.60119 ,  74.57375 ,\n",
       "       108.24419 , 103.96546 ,  90.313   , 100.47925 , 107.242805,\n",
       "       112.674515,  91.8922  ,  92.02104 ,  90.78944 , 111.67975 ,\n",
       "       104.15297 ,  90.41688 , 113.80492 ,  92.71728 ,  99.4185  ,\n",
       "       109.20762 ,  90.36739 , 112.66621 , 101.80723 ,  93.8617  ,\n",
       "       107.7599  ,  88.74226 ,  73.28674 , 108.34696 ,  90.24712 ,\n",
       "       110.071724, 101.09295 ,  98.79817 ,  91.81081 ,  92.5522  ,\n",
       "       104.282936,  93.63843 , 110.72926 ,  90.981834, 108.86677 ,\n",
       "        89.33931 ,  92.97573 ,  91.48153 , 106.24589 ,  90.39457 ,\n",
       "       109.27161 ,  90.764145,  89.27885 , 105.31935 ,  96.24591 ,\n",
       "       108.10183 ,  88.42495 ,  89.51227 , 101.80529 ,  92.37211 ,\n",
       "        91.48832 ,  94.96259 , 109.91914 ,  78.570816, 106.13675 ,\n",
       "        93.341286,  98.83867 , 109.03463 ,  93.26485 , 111.44952 ,\n",
       "        94.22784 , 101.20009 , 104.87741 ,  93.03312 , 101.96312 ,\n",
       "       102.3518  ,  87.02632 ,  93.73994 ,  92.87602 , 110.98154 ,\n",
       "        77.05497 , 106.51411 , 107.284386,  92.86899 , 108.548706,\n",
       "        91.052086,  91.41636 ,  74.60553 ,  93.59862 , 111.61184 ,\n",
       "        94.75331 ,  90.541176, 111.160324, 104.52874 ,  96.87912 ,\n",
       "        96.64396 ,  96.99395 ,  94.85269 , 106.76161 ,  87.643295,\n",
       "        93.983185,  88.9551  ,  93.35075 , 104.41048 ,  92.92029 ,\n",
       "        91.35246 ,  93.71898 , 113.306786,  90.16898 , 104.61857 ,\n",
       "        92.32725 ,  88.63633 , 110.744514, 101.29076 ,  99.24924 ,\n",
       "        95.218605, 106.78889 , 110.29595 ,  93.96692 ,  92.17725 ,\n",
       "       109.641846,  90.94349 , 107.2622  ,  89.48005 ,  95.159294,\n",
       "        92.009636, 108.07829 , 110.057   ,  90.98002 , 109.64611 ,\n",
       "        90.66986 , 109.802246,  90.25564 , 107.21862 ,  93.48874 ,\n",
       "        93.01696 , 103.35462 , 104.237404, 108.931625, 108.41301 ,\n",
       "       106.47735 ,  92.440674,  97.6454  , 107.38537 , 102.628746,\n",
       "        96.33299 ,  94.12918 , 102.451   ,  97.393936, 102.30191 ,\n",
       "       113.85987 ,  92.20066 , 106.93462 ,  92.17725 ,  91.58591 ,\n",
       "        95.77648 ,  79.66552 ,  90.35774 ,  88.45834 , 103.53509 ,\n",
       "       107.371414,  97.55412 , 105.65151 , 100.09809 ,  95.029015,\n",
       "       109.42409 , 103.208305, 109.73378 ,  89.07824 , 114.73018 ,\n",
       "        95.79629 , 108.597305,  93.48874 , 106.75001 ,  98.66059 ,\n",
       "        90.050995,  93.67466 , 102.5451  ,  96.17351 , 104.83663 ,\n",
       "        94.92141 , 114.66809 ,  87.8689  ,  88.791046, 106.07327 ,\n",
       "        93.80082 , 109.120026,  90.10071 ,  92.85788 , 108.95596 ,\n",
       "        94.96058 , 112.26101 ,  95.5819  , 114.5175  , 107.2622  ,\n",
       "       103.97563 ,  92.1865  ,  95.81047 ,  95.711395,  94.81227 ,\n",
       "        94.72723 ,  95.94498 , 107.67488 ,  87.97273 ,  92.68884 ,\n",
       "        96.4885  ,  93.371956, 113.2423  , 108.08661 ,  95.138664,\n",
       "        95.66676 ,  77.456375,  93.25849 , 103.2004  ,  89.908005,\n",
       "        98.17881 ,  96.82533 ,  95.331604, 102.628746,  93.25863 ,\n",
       "        92.323715, 108.00774 ,  91.28303 , 106.75001 ,  99.556465,\n",
       "       114.21724 , 102.23254 ,  78.57433 , 102.721375,  94.63506 ,\n",
       "        91.10002 , 106.75001 , 111.276505, 109.939384, 107.60119 ,\n",
       "        92.62396 , 107.2622  ,  95.82328 , 102.297424, 103.55077 ,\n",
       "        93.67466 ,  93.040535,  96.42318 ,  90.163445, 114.67563 ,\n",
       "        91.75531 ,  94.82929 ,  76.28111 , 109.14105 ,  91.53993 ,\n",
       "       108.07829 ,  89.390144,  91.33631 , 108.29687 ,  92.17257 ,\n",
       "       111.7361  ,  98.19717 ,  90.8894  ,  79.26885 , 107.688225,\n",
       "        94.80306 , 112.036415,  90.233055, 108.07829 ,  95.001045,\n",
       "        98.106544,  97.030266,  99.815765,  95.36514 , 111.50085 ,\n",
       "        89.21081 , 109.65239 , 106.459076,  93.10463 , 110.28362 ,\n",
       "        99.31374 , 103.97563 , 101.03611 ,  94.63506 , 107.688225,\n",
       "        94.406166, 102.85373 ,  99.14236 , 106.07411 , 108.61329 ,\n",
       "        97.37948 , 105.47595 ,  97.598335, 114.102066,  94.74913 ,\n",
       "        93.96832 , 112.74028 ,  97.21283 , 103.208305,  90.8894  ,\n",
       "        97.21283 , 103.67052 ,  96.77508 , 114.605995,  92.98535 ,\n",
       "        93.25779 , 109.5187  , 111.34156 , 104.32978 ,  95.20344 ,\n",
       "        89.629135, 107.2622  , 117.795494, 109.912735, 105.06538 ,\n",
       "        97.79839 ,  96.8222  , 104.32978 ,  93.576126,  97.02277 ,\n",
       "        96.38779 , 108.74292 , 111.776924,  91.77793 , 114.95606 ,\n",
       "       107.942116, 109.5187  ,  77.70063 , 109.17464 ,  95.32259 ,\n",
       "       109.58844 , 103.13276 ,  94.5617  ,  93.7686  , 112.509995,\n",
       "        97.10439 , 103.418434,  97.1885  ,  95.46501 ,  95.55044 ,\n",
       "       101.859406, 103.3656  ,  91.957794,  96.16021 ,  95.41122 ,\n",
       "       100.66731 ,  97.49857 , 115.39584 ,  93.83206 ,  97.88374 ,\n",
       "       101.70651 ,  96.66574 ,  96.01727 ,  94.15308 ,  92.46401 ,\n",
       "       114.54069 , 107.71203 ,  97.85333 ,  92.019264,  94.10121 ,\n",
       "        95.38029 , 102.295815, 111.610954, 103.699394, 104.66172 ,\n",
       "       105.87256 ,  81.3915  , 110.84867 ,  95.51328 , 108.5424  ,\n",
       "        97.046104, 105.85185 , 114.10085 , 109.859024, 107.189606,\n",
       "        88.12145 , 105.46828 , 104.92057 , 103.31738 , 110.40426 ,\n",
       "        95.80078 , 107.27834 , 107.082985, 110.455574,  91.40187 ,\n",
       "        94.31344 , 110.455574,  98.258095,  79.38798 ,  96.48353 ,\n",
       "       104.49169 ,  95.33671 , 113.62976 ,  88.79275 , 117.74697 ,\n",
       "        96.21692 ,  93.18372 , 115.11817 , 113.62976 ,  98.30754 ,\n",
       "       110.40426 , 106.5264  , 110.50737 , 110.245964, 110.857445,\n",
       "       108.06065 , 108.61818 ,  93.46182 , 113.447754,  81.23852 ,\n",
       "        92.50238 ,  98.165886,  91.77538 , 111.81144 , 105.29265 ,\n",
       "       108.4944  , 110.04474 ,  89.08908 ,  93.21122 , 114.66682 ,\n",
       "        92.508606,  95.32379 ,  97.11721 , 114.63957 ,  96.40856 ,\n",
       "       106.46439 ,  98.915924, 115.9029  , 109.20402 , 113.00997 ,\n",
       "        97.19884 ,  93.16889 ,  97.787605, 111.25843 ,  98.680786,\n",
       "        92.517075, 107.65796 , 113.65417 , 111.40307 , 109.65855 ,\n",
       "        97.77414 , 100.88933 ,  94.14592 ,  80.19494 , 100.22112 ,\n",
       "       111.58399 , 112.09142 , 111.332306, 113.414   , 103.78446 ,\n",
       "       101.75553 ,  80.55133 ,  91.284164, 114.43997 ,  95.60766 ,\n",
       "        94.139145, 111.93679 ,  95.20992 , 103.40688 ,  92.05216 ,\n",
       "        97.85333 ,  92.328224,  97.47259 ,  95.726265, 103.33604 ,\n",
       "        98.525185,  79.63251 ,  93.95669 ,  95.38029 , 114.80832 ,\n",
       "       108.67777 ,  96.82577 ,  93.828255, 109.380135,  95.49658 ,\n",
       "       108.5424  ,  79.884514,  99.815506,  94.315994, 108.72895 ,\n",
       "        95.755775, 108.45603 , 115.18567 ,  96.465546, 106.40353 ,\n",
       "        77.12527 , 111.72109 , 110.26303 , 112.019356, 108.5424  ,\n",
       "        92.904755,  95.18661 , 104.534706,  95.65357 , 102.391685,\n",
       "        88.79275 , 110.741776,  80.58591 , 107.617134,  97.67141 ,\n",
       "        93.1203  ,  93.95669 , 108.61818 , 110.455574, 115.874   ,\n",
       "        95.18661 ,  97.197105, 101.11711 , 112.54911 ,  94.66606 ,\n",
       "       110.40426 ,  96.09504 ,  80.585625,  97.91089 ,  91.498184,\n",
       "       103.74011 ,  79.884514,  96.72623 , 108.51058 , 108.90385 ,\n",
       "        97.25462 , 109.802765,  94.63156 , 105.05991 , 100.98147 ,\n",
       "        96.6401  , 108.5424  , 112.19309 , 105.68495 ,  96.68455 ,\n",
       "        97.80766 , 111.37962 ,  91.067505, 110.226204, 104.999435,\n",
       "       102.81004 , 109.438934,  92.988464, 102.14867 ,  97.47259 ,\n",
       "        96.74325 , 103.27593 , 103.59162 ,  93.229515, 112.46214 ,\n",
       "        93.72078 , 103.58506 ,  92.32617 , 110.706635,  95.02927 ,\n",
       "        94.966736, 110.455574, 106.36187 ,  77.46186 ,  93.46182 ,\n",
       "       109.960144,  93.70456 , 103.59162 ,  88.63878 , 110.93349 ,\n",
       "        92.91321 , 105.67219 , 116.035545,  91.88899 ,  96.6401  ,\n",
       "        94.3982  , 108.83036 ,  93.85162 , 105.56232 , 113.077446,\n",
       "        89.570206,  83.314674,  87.68174 , 102.61927 , 104.18429 ,\n",
       "        89.076996,  87.872536,  97.855034,  94.80679 ,  83.314674,\n",
       "        90.85532 , 100.72049 ,  90.848946, 100.09084 ,  88.019196,\n",
       "        99.2547  ,  87.84688 ,  88.0723  ,  91.18375 ,  88.39288 ,\n",
       "        74.63816 ,  91.462456,  76.75456 ,  88.29133 ,  60.95382 ,\n",
       "        80.360725,  81.662476,  83.86656 ,  72.16995 ,  96.528206,\n",
       "        72.47762 ,  72.403046,  89.44557 ,  86.327774,  74.03606 ,\n",
       "        90.76649 ,  78.11214 ,  71.89857 ,  76.30962 ,  92.04456 ,\n",
       "        91.927444,  85.715065,  85.95553 ,  72.89608 ,  81.152885,\n",
       "        74.53202 ,  79.81189 ,  95.60436 ,  79.80053 ,  71.47813 ,\n",
       "        89.79859 ,  79.5475  ,  87.87547 ,  73.00594 ,  91.94558 ,\n",
       "        82.75584 ,  86.327774,  71.57733 ,  80.37395 ,  78.301704,\n",
       "        87.04666 ,  73.00473 ,  91.28584 ,  68.945946,  67.03029 ,\n",
       "        84.866714,  77.38389 ,  65.7635  ,  74.27058 ,  75.32519 ,\n",
       "        57.720924,  91.518776,  91.31235 ,  87.13259 ,  73.256905,\n",
       "        90.40779 ,  75.397934,  82.45287 ,  90.435326,  75.79099 ,\n",
       "        59.851185,  75.161156,  76.27635 ,  86.327774,  80.61246 ,\n",
       "        80.37395 ,  86.327774,  78.64927 ,  91.02261 ,  80.465904,\n",
       "        77.432365,  72.20406 ,  80.58107 ,  76.47695 ,  90.081085,\n",
       "        61.95248 ,  90.28575 ,  83.44234 ,  78.41243 ,  85.90889 ,\n",
       "        85.95553 ,  78.6799  ,  68.39825 ,  69.44403 ,  77.722244,\n",
       "        80.12498 ,  78.669014,  91.21851 ,  85.56486 ,  81.33487 ,\n",
       "        78.80173 ,  72.37017 ,  82.007706,  72.51056 ,  79.80053 ,\n",
       "        78.26514 ,  88.59105 ,  78.49014 ,  75.67299 ,  77.37009 ,\n",
       "        79.80053 ,  86.88198 ,  74.47516 ,  80.40193 ,  90.11976 ,\n",
       "        94.60085 ,  70.62878 ,  85.834946,  85.20042 ,  87.29752 ,\n",
       "        73.967285,  80.70115 ], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = model_1.predict(val_dataset_1)\n",
    "tf.squeeze(model_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9284564-ca16-4170-b213-ade85baff54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108.21, 105.82, 108.19,  94.62, 110.46,  88.98, 108.84, 109.93,\n",
       "       104.89,  99.65, 103.19, 110.43, 107.74, 111.59,  91.38,  91.17,\n",
       "       109.6 , 107.53,  74.99,  86.25,  91.16,  88.59, 117.52,  85.55,\n",
       "        89.88, 117.36, 113.8 ,  92.42, 106.5 , 105.49, 118.27, 112.05,\n",
       "        92.73, 108.83,  98.91,  95.5 , 104.82,  88.28,  91.99,  73.74,\n",
       "        85.44,  89.94, 109.67,  89.06,  98.13,  92.55, 118.31, 114.23,\n",
       "        94.1 , 100.59, 108.97,  75.85,  89.08,  89.34, 108.68, 109.64,\n",
       "        88.05,  86.61, 112.8 , 107.43,  89.28, 112.83, 107.38,  92.05,\n",
       "        96.49,  87.12,  89.2 , 107.14,  88.08, 109.7 , 101.99,  96.98,\n",
       "        90.84, 103.11, 110.16, 139.07,  92.44, 109.42,  96.82,  98.81,\n",
       "       104.18, 109.66,  89.8 , 107.93,  96.41,  87.  , 109.31,  89.69,\n",
       "       100.11,  97.28, 107.48,  88.05,  77.23, 106.72,  86.81, 109.34,\n",
       "       111.51,  93.81, 100.8 ,  96.26,  97.14,  98.03,  76.56, 129.65,\n",
       "        89.15,  97.93, 106.1 ,  86.73,  97.63, 107.85,  88.98,  95.98,\n",
       "        92.07,  89.19,  89.99,  87.44,  88.99, 107.94,  84.76,  75.19,\n",
       "        89.94, 104.55,  96.56, 108.74, 106.45, 114.23,  89.22,  85.89,\n",
       "       113.77,  92.41,  89.49, 109.13,  74.87,  90.2 ,  98.74,  88.7 ,\n",
       "        89.98,  99.55,  90.22,  90.94, 116.75,  91.33,  96.65, 100.05,\n",
       "       100.01, 121.57, 105.03,  89.62, 111.49,  90.86, 100.59,  88.38,\n",
       "       118.87,  89.08,  73.24, 110.66, 106.93,  96.79, 101.17, 110.59,\n",
       "       124.6 ,  92.04,  91.57,  88.46, 108.8 , 112.26,  96.6 , 109.81,\n",
       "        97.74, 100.1 , 112.19,  89.59, 109.85, 101.9 ,  92.19, 112.12,\n",
       "        98.25,  76.32, 107.68, 100.1 , 113.83, 105.28,  98.04,  93.17,\n",
       "       115.32, 100.78,  94.84,  98.75,  90.85, 103.99,  87.4 ,  97.12,\n",
       "        90.76, 118.72, 100.29, 110.36,  91.52,  93.17, 114.71,  90.59,\n",
       "       109.33,  93.25,  94.47, 104.25,  90.14,  93.71,  99.48, 109.54,\n",
       "        73.83, 108.23,  94.59,  98.1 , 107.5 ,  91.39, 120.76,  93.96,\n",
       "       107.93, 105.65,  89.79, 116.79, 111.17,  90.8 ,  85.74,  93.51,\n",
       "       106.88,  74.17, 108.83, 114.12,  95.73, 105.64,  89.23,  91.7 ,\n",
       "        75.54, 100.52, 107.98,  89.83, 104.31, 110.84, 115.04, 100.98,\n",
       "        90.41,  98.12, 101.65, 105.57,  90.65,  91.01,  93.2 ,  94.77,\n",
       "        98.16,  90.28,  92.49,  91.82, 117.59,  87.06,  99.48,  90.27,\n",
       "        88.59, 106.97,  96.19, 121.31,  92.83,  97.07, 108.61, 106.77,\n",
       "        88.86, 107.44,  91.63, 116.13,  88.34,  87.22,  89.06, 128.3 ,\n",
       "       105.06,  91.4 , 106.82,  88.93, 111.02,  87.24, 131.67,  89.18,\n",
       "        91.49, 119.38, 110.5 , 107.47, 109.66, 112.34,  89.12,  93.39,\n",
       "       116.28, 101.52,  90.02,  91.41, 103.32, 115.  , 107.63, 128.8 ,\n",
       "        90.51, 106.96,  92.59,  87.58, 103.7 ,  75.86,  87.9 ,  88.  ,\n",
       "       104.85, 112.89, 110.32, 111.16,  96.96,  93.71, 108.58, 109.51,\n",
       "       104.69,  90.58, 106.47,  89.06, 104.87,  91.13, 100.21, 100.39,\n",
       "        93.83,  86.66, 111.64,  86.27,  96.53,  92.58, 116.13,  90.21,\n",
       "        94.68, 103.93,  84.48, 108.15,  91.16, 114.16, 102.51,  91.56,\n",
       "       107.05, 105.73, 116.68, 104.57, 100.33,  84.8 ,  89.35,  91.88,\n",
       "        88.77,  91.65, 109.17, 111.85,  94.41,  97.34,  94.53,  90.03,\n",
       "       105.46, 105.65,  89.05,  87.49,  84.86,  91.4 ,  97.02,  92.98,\n",
       "        92.51,  97.87,  89.79,  98.64,  94.1 ,  90.05, 105.91,  90.98,\n",
       "       100.21,  88.15, 118.44, 126.17,  77.5 , 101.56,  91.17,  92.64,\n",
       "       109.67, 155.62, 108.16,  99.8 ,  87.8 , 114.08,  87.52,  98.85,\n",
       "       102.71, 102.45,  89.05,  95.72,  91.77, 111.91,  85.86,  88.19,\n",
       "        75.38, 109.21, 117.71, 107.34,  89.12,  98.44, 108.2 ,  84.22,\n",
       "       110.88,  90.2 ,  97.16,  75.41, 114.73,  91.92, 136.75,  90.46,\n",
       "       106.74,  90.99,  90.18,  90.24, 102.39,  86.94, 108.58,  86.47,\n",
       "       105.41, 110.05,  92.57, 109.11,  90.11, 100.61, 114.44,  93.67,\n",
       "       109.18,  92.59,  97.97,  90.78, 107.37, 108.06,  87.14, 105.18,\n",
       "        98.56, 108.41,  94.4 ,  88.63, 114.46, 104.22,  99.86,  88.13,\n",
       "       103.91,  98.61,  99.35, 120.9 ,  89.34,  99.06, 105.4 , 114.01,\n",
       "       101.12,  94.86,  91.88, 116.36, 111.22, 104.95, 101.32, 103.9 ,\n",
       "        90.01, 108.4 ,  96.93,  90.22,  92.25, 105.54, 114.47,  89.46,\n",
       "       120.12,  95.75, 110.74,  78.1 , 106.82,  92.34, 115.31,  97.32,\n",
       "        87.25,  92.31, 115.18,  89.26, 112.76,  90.91, 100.68,  88.83,\n",
       "        92.2 , 115.33,  88.86,  89.28,  90.18,  99.12,  92.81, 112.53,\n",
       "        88.58,  90.42, 115.88,  87.99,  85.2 ,  88.32,  88.7 , 112.32,\n",
       "       104.18,  87.75,  92.38,  88.72,  92.41, 105.28, 118.86, 100.03,\n",
       "        97.98,  99.86,  77.41, 107.16,  90.45, 108.43,  94.27, 100.49,\n",
       "       111.34, 110.1 , 103.5 ,  75.39, 106.19, 105.29,  93.86, 109.99,\n",
       "        88.96,  97.09, 100.37, 104.89,  94.41,  89.37, 104.93,  90.53,\n",
       "        73.36,  89.04,  95.74, 104.42, 126.52,  85.59, 113.91,  87.14,\n",
       "        83.96, 113.65, 103.31,  84.72, 108.7 , 100.93, 112.88, 105.76,\n",
       "       121.22, 100.68, 125.45,  88.28, 109.62,  77.11,  89.14,  92.02,\n",
       "        86.93, 105.43,  98.01, 102.29, 108.08,  91.32, 122.28, 108.71,\n",
       "        92.02,  87.91,  90.49, 113.83,  85.82, 106.16, 102.56, 112.36,\n",
       "        97.85, 106.02,  92.8 ,  87.76,  84.9 , 108.9 ,  92.43,  93.77,\n",
       "       110.74, 112.49, 103.86, 110.57,  92.11, 109.38,  88.6 ,  73.76,\n",
       "       110.93, 105.72, 104.09, 113.67, 107.65,  92.97,  96.44,  75.86,\n",
       "        86.1 , 103.32, 100.12,  87.71, 102.91,  86.38, 101.18, 115.15,\n",
       "        88.75,  96.87,  87.22,  84.12,  99.74,  87.2 ,  74.62,  89.96,\n",
       "        88.85, 110.44, 110.71,  94.88,  87.84, 142.46,  93.31, 106.36,\n",
       "        74.08,  90.44,  86.41, 117.4 ,  86.77, 121.84, 109.32, 101.81,\n",
       "       103.08,  76.64, 103.62, 107.44, 107.13, 108.82,  92.9 ,  87.68,\n",
       "       100.9 ,  97.71, 103.06,  94.01, 115.41,  77.77, 108.43,  93.59,\n",
       "        88.38,  89.25, 108.69, 109.58, 111.58,  88.53,  90.18,  96.76,\n",
       "       105.36,  89.38, 106.58,  89.46,  74.75,  92.22,  92.48, 106.4 ,\n",
       "        82.44,  91.81, 115.45, 109.09,  86.18, 110.22,  91.3 , 103.85,\n",
       "        99.38,  89.71, 108.57, 111.86, 111.68,  94.99,  86.4 , 105.78,\n",
       "        89.06, 115.14, 106.62,  99.66, 125.1 ,  95.5 , 101.69,  87.94,\n",
       "        89.68,  97.93, 100.87,  93.5 , 114.58,  87.33, 118.41,  98.37,\n",
       "       106.  ,  89.58,  88.51, 109.5 ,  97.99,  75.9 , 111.1 , 112.12,\n",
       "       115.88, 104.72,  91.94, 114.8 ,  87.13,  98.86, 121.65,  86.04,\n",
       "        85.68,  91.38, 103.93,  88.71, 103.07, 105.68, 110.58,  86.96,\n",
       "        92.26, 112.97, 104.88,  88.51,  89.6 ,  97.43,  99.68,  95.1 ,\n",
       "        89.93, 100.89, 101.34, 111.83,  90.84, 100.04,  86.51,  85.09,\n",
       "        88.65,  89.06,  88.03, 103.89,  92.22, 106.05,  73.25,  90.13,\n",
       "        90.11, 107.29,  92.72, 113.1 , 100.08,  85.17, 114.58, 118.41,\n",
       "        85.14, 112.32,  97.74,  88.25,  85.91, 105.29, 106.38, 112.03,\n",
       "       108.72,  88.66,  91.11,  89.38,  85.91, 117.85,  90.82,  87.78,\n",
       "       108.05,  93.8 , 118.54,  84.42, 106.79, 108.66, 105.04,  93.5 ,\n",
       "        95.58,  96.11, 102.86, 107.29, 104.26,  86.48,  88.63, 106.3 ,\n",
       "        85.84,  94.91,  88.44,  99.91,  77.38, 106.53, 111.15, 105.61,\n",
       "        89.04, 103.62,  94.71,  88.51, 106.34,  89.53,  82.79,  87.43,\n",
       "        88.54, 108.75,  96.45,  99.74, 104.42,  88.77, 105.1 ,  99.52,\n",
       "        91.76,  91.96,  93.83,  96.85, 118.81,  76.44, 101.86, 104.29,\n",
       "        87.23, 149.52, 106.61,  99.68,  85.93,  90.45,  90.06,  90.38,\n",
       "        95.56, 109.  , 109.64, 131.98,  98.15, 102.33, 102.42,  89.11,\n",
       "        88.93, 103.03, 107.24,  91.13,  86.23,  99.93,  89.25,  97.09,\n",
       "        88.24, 108.59, 107.39, 123.34,  85.71, 107.39, 108.77, 109.22,\n",
       "        87.48, 110.85])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf531bda-a184-4598-a485-5f22d93b4bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25526499305413186"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_r2 = r2_score(val_target, tf.squeeze(model_1_preds))\n",
    "model_1_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e7535d4-5524-47e5-9d3d-35c5cc9c2253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.182545],\n",
       "       [73.1666  ],\n",
       "       [61.186077],\n",
       "       ...,\n",
       "       [77.87312 ],\n",
       "       [84.02927 ],\n",
       "       [76.05273 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_test_preds = model_1.predict(test_data.drop(\"ID\", axis=1).to_numpy())\n",
    "model_1_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72746786-79d0-47c6-9212-399d7129cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.clone_model(model_1)\n",
    "model_2._name = \"model_2_lr_scheduler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54fb1d9f-f408-4d0c-855a-7b38dee4f640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.1303 - val_loss: 9.5435 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0012589254117941673.\n",
      "Epoch 2/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.1257 - val_loss: 9.5370 - lr: 0.0013\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0015848931924611136.\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1250 - val_loss: 9.5354 - lr: 0.0016\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0019952623149688794.\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1243 - val_loss: 9.5336 - lr: 0.0020\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0025118864315095803.\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1227 - val_loss: 9.5268 - lr: 0.0025\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0031622776601683794.\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.0423 - val_loss: 6.8466 - lr: 0.0032\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0039810717055349725.\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1534 - val_loss: 5.3469 - lr: 0.0040\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.005011872336272722.\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.8036 - val_loss: 5.1504 - lr: 0.0050\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.006309573444801934.\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6596 - val_loss: 5.0607 - lr: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.007943282347242816.\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.5941 - val_loss: 4.9521 - lr: 0.0079\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.6508 - val_loss: 4.9679 - lr: 0.0100\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.012589254117941675.\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6444 - val_loss: 4.8661 - lr: 0.0126\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.015848931924611134.\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.5736 - val_loss: 4.8340 - lr: 0.0158\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0199526231496888.\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.5510 - val_loss: 4.8106 - lr: 0.0200\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.025118864315095794.\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.5289 - val_loss: 4.7758 - lr: 0.0251\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.03162277660168379.\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.5650 - val_loss: 5.0668 - lr: 0.0316\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.039810717055349734.\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.7116 - val_loss: 4.8132 - lr: 0.0398\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.05011872336272723.\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.7857 - val_loss: 5.3050 - lr: 0.0501\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.06309573444801933.\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8012 - val_loss: 4.9772 - lr: 0.0631\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.07943282347242814.\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8554 - val_loss: 7.0397 - lr: 0.0794\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_2_history = model_2.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=20,\n",
    "                              callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08de17e2-b13d-43ac-8893-c4ffafbca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bb5655f-ca4b-4c1f-92ae-a14a5bb50341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model_2_history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "898847c1-8101-4aae-a85a-095cd009e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25c5c91ce80>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-3 * 10 ** (tf.range(20)/10)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.semilogx(lrs, model_2_history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36b600f7-53d5-4f80-ac47-c36c8f333419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
       "array([0.0001    , 0.00012589, 0.00015849, 0.00019953, 0.00025119,\n",
       "       0.00031623, 0.00039811, 0.00050119, 0.00063096, 0.00079433])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c38f6710-7943-438d-be86-1740f7b6ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Categorical, Real\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "dda0954a-b63a-4d44-9e54-39209957918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(num_dense_layers,\n",
    "              num_dense_nodes,\n",
    "              activation,\n",
    "              learning_rate,\n",
    "              kernel):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    print(f\"\\nnum_dense_layers: {num_dense_layers}\\nnum_dense_nodes: {num_dense_nodes}\\nactivation: {activation}\\nlearning_rate: {learning_rate}\\nkernel: {kernel}\\n\")\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Input(shape=(376,), dtype=tf.float32))\n",
    "    model.add(layers.Rescaling(1/255.))\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(layers.Dense(num_dense_nodes, kernel_initializer=kernel, activation=activation))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss=\"mae\",\n",
    "                  optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bdef0267-b449-4e2f-a11f-2a40a0c0996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_num_dense_layers = Integer(low=1, high=10, name=\"num_dense_layers\")\n",
    "dim_num_dense_nodes = Integer(low=128, high=968, name=\"num_dense_nodes\")\n",
    "dim_activation = Categorical(categories=[\"relu\", \"tanh\"], name=\"activation\")\n",
    "dim_learning_rate = Real(low=1e-3, high=1e-2, name=\"learning_rate\")\n",
    "dim_dense_kernel = Categorical(categories=[\"glorot_normal\", \"glorot_uniform\", \"he_normal\", \"he_uniform\"], name=\"kernel\")\n",
    "\n",
    "param_grid = [dim_num_dense_layers, dim_num_dense_nodes, dim_activation, dim_learning_rate, dim_dense_kernel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b4e490f2-0d45-4be7-b91a-468002ff4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mae = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "224a0a8d-7ef6-46d7-83c5-204ab94d666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "\n",
    "    model = create_nn(**params)\n",
    "\n",
    "    history = model.fit(train_dataset_1,\n",
    "                        validation_data=val_dataset_1,\n",
    "                        epochs=10)\n",
    "\n",
    "    mae = history.history[\"val_loss\"][-1]\n",
    "\n",
    "    print(f\"\\nMAE: {mae}\\n\")\n",
    "\n",
    "    del model\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6ee280f7-a85d-4503-bddd-4a885524290a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.001\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 99.7193 - val_loss: 95.2453\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 92.8291 - val_loss: 84.5895\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 78.9019 - val_loss: 66.6157\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 57.8825 - val_loss: 41.4723\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 30.3390 - val_loss: 12.6103\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 12.1166 - val_loss: 10.0554\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.9867 - val_loss: 10.0052\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.7871 - val_loss: 9.8256\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.6013 - val_loss: 9.6289\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.4212 - val_loss: 9.4438\n",
      "\n",
      "MAE: 9.443755149841309\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.443755149841309"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_parameters = [1, 128, \"relu\", 1e-3, \"glorot_normal\"]\n",
    "objective(x=initial_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0cd338a0-4469-4b8d-835d-1b52feabed0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.001\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 99.7151 - val_loss: 95.2671\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 92.9496 - val_loss: 84.8760\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 79.3875 - val_loss: 67.3919\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 58.9399 - val_loss: 42.9393\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 32.0295 - val_loss: 13.9428\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 12.5220 - val_loss: 10.0350\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 11.0176 - val_loss: 10.0307\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.8143 - val_loss: 9.8459\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.6309 - val_loss: 9.6569\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.4515 - val_loss: 9.4776\n",
      "\n",
      "MAE: 9.477619171142578\n",
      "\n",
      "\n",
      "num_dense_layers: 8\n",
      "num_dense_nodes: 282\n",
      "activation: tanh\n",
      "learning_rate: 0.006371651421518384\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 26.0333 - val_loss: 9.5100\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1668 - val_loss: 9.5006\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1744 - val_loss: 9.5042\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1826 - val_loss: 9.5148\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1863 - val_loss: 9.5349\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1941 - val_loss: 9.5403\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1965 - val_loss: 9.5563\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2037 - val_loss: 9.5569\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1960 - val_loss: 9.5225\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2023 - val_loss: 9.5135\n",
      "\n",
      "MAE: 9.513542175292969\n",
      "\n",
      "\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 514\n",
      "activation: relu\n",
      "learning_rate: 0.0022858013612974673\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 32.2903 - val_loss: 8.4122\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.7355 - val_loss: 6.6931\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.8844 - val_loss: 6.1449\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.4433 - val_loss: 5.7097\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2235 - val_loss: 5.5940\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.1148 - val_loss: 5.6112\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.9626 - val_loss: 5.4638\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.8105 - val_loss: 5.4421\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.7866 - val_loss: 5.4442\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.7518 - val_loss: 5.4221\n",
      "\n",
      "MAE: 5.422127723693848\n",
      "\n",
      "\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 734\n",
      "activation: tanh\n",
      "learning_rate: 0.001007008892569129\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 38.8584 - val_loss: 9.6290\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1726 - val_loss: 9.5214\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1691 - val_loss: 9.5154\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1667 - val_loss: 9.5068\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1648 - val_loss: 9.5005\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1668 - val_loss: 9.4991\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1661 - val_loss: 9.4953\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1652 - val_loss: 9.4922\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1652 - val_loss: 9.4900\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1620 - val_loss: 9.4836\n",
      "\n",
      "MAE: 9.483613014221191\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 642\n",
      "activation: relu\n",
      "learning_rate: 0.001207561825372742\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 16.9211 - val_loss: 16.8845\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.9955 - val_loss: 9.9502\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.7835 - val_loss: 9.3634\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3643 - val_loss: 11.4524\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7911 - val_loss: 9.9745\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0258 - val_loss: 7.4930\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.0668 - val_loss: 6.6844\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7302 - val_loss: 8.6421\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9079 - val_loss: 7.8426\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3528 - val_loss: 7.3889\n",
      "\n",
      "MAE: 7.38886833190918\n",
      "\n",
      "\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 167\n",
      "activation: tanh\n",
      "learning_rate: 0.003094942063872739\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 60.2498 - val_loss: 28.5046\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 14.4263 - val_loss: 9.5314\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1543 - val_loss: 9.5263\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1539 - val_loss: 9.5244\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1550 - val_loss: 9.5294\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1561 - val_loss: 9.5287\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1564 - val_loss: 9.5244\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1565 - val_loss: 9.5254\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1571 - val_loss: 9.5257\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.1584 - val_loss: 9.5258\n",
      "\n",
      "MAE: 9.52583122253418\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 449\n",
      "activation: tanh\n",
      "learning_rate: 0.005200866039231821\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 21.2033 - val_loss: 9.5030\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1838 - val_loss: 9.5155\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1848 - val_loss: 9.5182\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1956 - val_loss: 9.5190\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2024 - val_loss: 9.5080\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2034 - val_loss: 9.4958\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2083 - val_loss: 9.4977\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.1978 - val_loss: 9.5158\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.1965 - val_loss: 9.5213\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.2085 - val_loss: 9.5184\n",
      "\n",
      "MAE: 9.518359184265137\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 506\n",
      "activation: relu\n",
      "learning_rate: 0.009479815801163676\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 29.9714 - val_loss: 10.2090\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.7379 - val_loss: 8.3674\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3710 - val_loss: 5.9608\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7821 - val_loss: 8.9741\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.9258 - val_loss: 15.4893\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7935 - val_loss: 5.0952\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1593 - val_loss: 10.1044\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.9654 - val_loss: 4.7967\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3758 - val_loss: 5.3734\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9798 - val_loss: 4.4645\n",
      "\n",
      "MAE: 4.464505195617676\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 141\n",
      "activation: relu\n",
      "learning_rate: 0.003169229194234106\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 24.8432 - val_loss: 7.1914\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.2901 - val_loss: 5.8969\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.6741 - val_loss: 5.7406\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0231 - val_loss: 6.5022\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9131 - val_loss: 6.6155\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8901 - val_loss: 5.5755\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0073 - val_loss: 6.2366\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8428 - val_loss: 6.0815\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9404 - val_loss: 5.3945\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9686 - val_loss: 5.4238\n",
      "\n",
      "MAE: 5.423820972442627\n",
      "\n",
      "\n",
      "num_dense_layers: 6\n",
      "num_dense_nodes: 828\n",
      "activation: relu\n",
      "learning_rate: 0.004519545468159168\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 22.0262 - val_loss: 24.8226\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.8507 - val_loss: 9.0675\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.9935 - val_loss: 5.6144\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.4880 - val_loss: 10.6020\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1325 - val_loss: 7.0554\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0511 - val_loss: 5.2468\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1460 - val_loss: 9.7349\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4456 - val_loss: 5.0402\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2322 - val_loss: 12.0312\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4944 - val_loss: 7.5574\n",
      "\n",
      "MAE: 7.557368755340576\n",
      "\n",
      "\n",
      "num_dense_layers: 8\n",
      "num_dense_nodes: 485\n",
      "activation: relu\n",
      "learning_rate: 0.0061093029503799245\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 8ms/step - loss: 26.3950 - val_loss: 8.2108\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.3351 - val_loss: 6.7558\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.5632 - val_loss: 15.9502\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.5790 - val_loss: 10.1699\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1700 - val_loss: 4.6811\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7780 - val_loss: 7.7779\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2616 - val_loss: 6.0988\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5440 - val_loss: 4.4539\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4243 - val_loss: 7.7876\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9897 - val_loss: 9.0579\n",
      "\n",
      "MAE: 9.057886123657227\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.008498840471693612\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 60.8500 - val_loss: 10.2889\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.4944 - val_loss: 8.6425\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 9.2360 - val_loss: 7.6481\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 8.3106 - val_loss: 6.9964\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5625 - val_loss: 6.5418\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.0450 - val_loss: 6.2690\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.6861 - val_loss: 5.9790\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4327 - val_loss: 5.8237\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2641 - val_loss: 5.5797\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1503 - val_loss: 5.4678\n",
      "\n",
      "MAE: 5.467778205871582\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 30.1945 - val_loss: 8.2794\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 8.3295 - val_loss: 6.4863\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.9173 - val_loss: 6.4524\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.3987 - val_loss: 5.9296\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.0541 - val_loss: 5.5450\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.9306 - val_loss: 5.4977\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.7903 - val_loss: 5.5181\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.7113 - val_loss: 5.3967\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.5740 - val_loss: 5.3155\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.5424 - val_loss: 5.2422\n",
      "\n",
      "MAE: 5.242249011993408\n",
      "\n",
      "\n",
      "num_dense_layers: 10\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 29.1641 - val_loss: 9.3997\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 9.0130 - val_loss: 7.8179\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.0724 - val_loss: 12.9001\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.4173 - val_loss: 9.4755\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.8872 - val_loss: 5.1729\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6871 - val_loss: 5.3525\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.2966 - val_loss: 9.1173\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.5724 - val_loss: 9.1175\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.1666 - val_loss: 9.1322\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.2260 - val_loss: 7.6808\n",
      "\n",
      "MAE: 7.680779933929443\n",
      "\n",
      "\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.008645437913174462\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 18.4221 - val_loss: 8.6304\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8260 - val_loss: 10.8284\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9374 - val_loss: 11.8787\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5784 - val_loss: 9.1665\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6876 - val_loss: 5.8549\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5544 - val_loss: 9.3968\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8981 - val_loss: 8.9318\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6039 - val_loss: 6.0803\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.8349 - val_loss: 6.6110\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.7383 - val_loss: 7.4753\n",
      "\n",
      "MAE: 7.475337028503418\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 920\n",
      "activation: relu\n",
      "learning_rate: 0.0025735591060336302\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 68.5112 - val_loss: 11.1652\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.6912 - val_loss: 8.9629\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.5280 - val_loss: 7.9651\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.6558 - val_loss: 7.2627\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.9318 - val_loss: 6.8476\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3805 - val_loss: 6.4924\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.9628 - val_loss: 6.2517\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6594 - val_loss: 5.9993\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4584 - val_loss: 5.8447\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3151 - val_loss: 5.7948\n",
      "\n",
      "MAE: 5.794794082641602\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 920\n",
      "activation: relu\n",
      "learning_rate: 0.002043608374641198\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 79.5555 - val_loss: 26.3488\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 12.1730 - val_loss: 9.4466\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.0687 - val_loss: 8.6179\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.2472 - val_loss: 7.8325\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.6072 - val_loss: 7.2875\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.0265 - val_loss: 6.8943\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.5341 - val_loss: 6.5791\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1874 - val_loss: 6.3188\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.8925 - val_loss: 6.1342\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6522 - val_loss: 5.9856\n",
      "\n",
      "MAE: 5.985588550567627\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 959\n",
      "activation: relu\n",
      "learning_rate: 0.00924881668135603\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 31.6857 - val_loss: 8.4257\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5087 - val_loss: 6.7366\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0483 - val_loss: 5.9863\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4178 - val_loss: 6.1350\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1805 - val_loss: 6.0345\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9364 - val_loss: 5.6369\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7866 - val_loss: 5.3796\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6563 - val_loss: 5.2997\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.5643 - val_loss: 5.2876\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.5550 - val_loss: 5.2305\n",
      "\n",
      "MAE: 5.230503082275391\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 534\n",
      "activation: relu\n",
      "learning_rate: 0.007722287360318004\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 41.9318 - val_loss: 9.2288\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.4188 - val_loss: 7.4364\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.8101 - val_loss: 6.3531\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.9028 - val_loss: 5.8172\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4297 - val_loss: 5.4781\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1462 - val_loss: 5.2649\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9335 - val_loss: 5.1448\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8399 - val_loss: 4.9977\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7142 - val_loss: 4.9440\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6889 - val_loss: 4.8994\n",
      "\n",
      "MAE: 4.899422645568848\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 965\n",
      "activation: relu\n",
      "learning_rate: 0.008717332002102311\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 32.0314 - val_loss: 8.4160\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.4832 - val_loss: 6.7498\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0990 - val_loss: 5.9814\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4842 - val_loss: 6.0709\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2320 - val_loss: 5.8897\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9840 - val_loss: 5.5744\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8227 - val_loss: 5.6226\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7187 - val_loss: 5.5980\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6798 - val_loss: 5.5209\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6466 - val_loss: 5.4115\n",
      "\n",
      "MAE: 5.411526679992676\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 627\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 15.3026 - val_loss: 6.5742\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 11.8903 - val_loss: 5.2331\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.9177 - val_loss: 12.0765\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.0596 - val_loss: 9.1874\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.4536 - val_loss: 6.1894\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.3443 - val_loss: 5.4867\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5797 - val_loss: 5.5566\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5895 - val_loss: 10.4025\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0282 - val_loss: 7.0153\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3224 - val_loss: 4.7892\n",
      "\n",
      "MAE: 4.789168357849121\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 234\n",
      "activation: relu\n",
      "learning_rate: 0.0015658705665671272\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 97.9607 - val_loss: 89.3420\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 77.9835 - val_loss: 56.8756\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 35.5254 - val_loss: 10.2828\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 11.1537 - val_loss: 9.9241\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.7231 - val_loss: 9.5717\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.3915 - val_loss: 9.2248\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.0863 - val_loss: 8.9293\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 9.7862 - val_loss: 8.6527\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.4856 - val_loss: 8.3335\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 9.2256 - val_loss: 8.0729\n",
      "\n",
      "MAE: 8.072916984558105\n",
      "\n",
      "\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 630\n",
      "activation: relu\n",
      "learning_rate: 0.007894316498019667\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 13.5932 - val_loss: 8.7179\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.0235 - val_loss: 13.4227\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.0873 - val_loss: 6.2854\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.9343 - val_loss: 7.1384\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.7711 - val_loss: 6.1369\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.8887 - val_loss: 7.5540\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.4319 - val_loss: 9.4921\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1106 - val_loss: 6.0781\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5042 - val_loss: 7.4336\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.0214 - val_loss: 6.9719\n",
      "\n",
      "MAE: 6.971884250640869\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 8ms/step - loss: 26.5756 - val_loss: 11.6674\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.1659 - val_loss: 13.4824\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6329 - val_loss: 9.4486\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8795 - val_loss: 12.2430\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7080 - val_loss: 6.6753\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7444 - val_loss: 5.7955\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3555 - val_loss: 5.9767\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8462 - val_loss: 7.0373\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.0039 - val_loss: 10.3997\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0552 - val_loss: 5.8148\n",
      "\n",
      "MAE: 5.814815044403076\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 5ms/step - loss: 29.9998 - val_loss: 8.2770\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 8.3374 - val_loss: 6.5017\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.8620 - val_loss: 6.3169\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.3541 - val_loss: 5.7697\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0555 - val_loss: 5.5715\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9070 - val_loss: 5.4669\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7971 - val_loss: 5.5893\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7315 - val_loss: 5.2491\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.5637 - val_loss: 5.2676\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.5101 - val_loss: 5.1734\n",
      "\n",
      "MAE: 5.173369407653809\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 894\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 85.6293 - val_loss: 16.2221\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.8794 - val_loss: 15.6925\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.0891 - val_loss: 5.7451\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.6020 - val_loss: 6.1732\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3365 - val_loss: 7.6436\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3330 - val_loss: 7.2627\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9628 - val_loss: 4.9345\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1170 - val_loss: 9.2793\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0479 - val_loss: 4.5095\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9331 - val_loss: 11.1062\n",
      "\n",
      "MAE: 11.10615062713623\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 755\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 32.7922 - val_loss: 8.4336\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 8.5512 - val_loss: 6.8012\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 7.0736 - val_loss: 5.9596\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.4381 - val_loss: 5.8856\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.1785 - val_loss: 5.8655\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9737 - val_loss: 5.6338\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8295 - val_loss: 5.6375\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7593 - val_loss: 5.6368\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.6784 - val_loss: 5.4257\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.5681 - val_loss: 5.4904\n",
      "\n",
      "MAE: 5.490410804748535\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 409\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 24.1328 - val_loss: 12.3609\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.5366 - val_loss: 6.2006\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.7357 - val_loss: 5.8144\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.5056 - val_loss: 4.8220\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2888 - val_loss: 4.5091\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.4660 - val_loss: 5.0636\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1771 - val_loss: 7.6734\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4587 - val_loss: 5.1730\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7910 - val_loss: 9.5690\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6762 - val_loss: 6.9707\n",
      "\n",
      "MAE: 6.970746994018555\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 548\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 27.4568 - val_loss: 7.7683\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.9795 - val_loss: 11.9863\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.4066 - val_loss: 10.4145\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.6730 - val_loss: 12.0088\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4125 - val_loss: 6.4643\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.8575 - val_loss: 5.4754\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1664 - val_loss: 12.8502\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8279 - val_loss: 7.1800\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4130 - val_loss: 6.3864\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2359 - val_loss: 7.6180\n",
      "\n",
      "MAE: 7.61796760559082\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 714\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 21.4823 - val_loss: 9.0222\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 11.8401 - val_loss: 25.3971\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.1375 - val_loss: 5.8273\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1551 - val_loss: 6.2856\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7229 - val_loss: 4.5062\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9757 - val_loss: 7.4424\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3043 - val_loss: 4.9327\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1192 - val_loss: 8.1935\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7288 - val_loss: 8.3319\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1732 - val_loss: 6.4775\n",
      "\n",
      "MAE: 6.477477073669434\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 270\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 29.9521 - val_loss: 12.6911\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.9256 - val_loss: 5.7696\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1401 - val_loss: 8.8745\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.2113 - val_loss: 4.8249\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.7498 - val_loss: 7.1644\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.8051 - val_loss: 5.4478\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7336 - val_loss: 5.3258\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7196 - val_loss: 8.2439\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1959 - val_loss: 7.5182\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2856 - val_loss: 6.3223\n",
      "\n",
      "MAE: 6.322254180908203\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 442\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 37.5379 - val_loss: 8.9689\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 9.0609 - val_loss: 7.0658\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5532 - val_loss: 6.2248\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.7327 - val_loss: 5.7172\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.3525 - val_loss: 5.4709\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.0697 - val_loss: 5.3039\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.9261 - val_loss: 5.2668\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8206 - val_loss: 5.1681\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7163 - val_loss: 5.1942\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.6509 - val_loss: 5.1304\n",
      "\n",
      "MAE: 5.1304216384887695\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 480\n",
      "activation: relu\n",
      "learning_rate: 0.008646246748781138\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 18.8945 - val_loss: 8.7596\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.4417 - val_loss: 6.8705\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.9137 - val_loss: 8.0091\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.6890 - val_loss: 12.4961\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9858 - val_loss: 8.5805\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4097 - val_loss: 6.7334\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2364 - val_loss: 5.2861\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9867 - val_loss: 8.4556\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3158 - val_loss: 7.9674\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.2613 - val_loss: 4.9617\n",
      "\n",
      "MAE: 4.961721897125244\n",
      "\n",
      "\n",
      "num_dense_layers: 6\n",
      "num_dense_nodes: 506\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 23.7872 - val_loss: 10.8805\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.1687 - val_loss: 9.7496\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3879 - val_loss: 4.9755\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.7306 - val_loss: 7.2788\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4555 - val_loss: 8.7024\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.4045 - val_loss: 13.8349\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9354 - val_loss: 11.8094\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8422 - val_loss: 5.1624\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8813 - val_loss: 9.1294\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3967 - val_loss: 9.1364\n",
      "\n",
      "MAE: 9.136445999145508\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 711\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 32.8248 - val_loss: 8.4979\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.5686 - val_loss: 6.7912\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1646 - val_loss: 5.9784\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5077 - val_loss: 5.7842\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1746 - val_loss: 5.7886\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.0157 - val_loss: 5.6163\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8371 - val_loss: 5.5753\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.7350 - val_loss: 5.3890\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6396 - val_loss: 5.5460\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.6692 - val_loss: 5.6717\n",
      "\n",
      "MAE: 5.671742916107178\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 660\n",
      "activation: relu\n",
      "learning_rate: 0.0036538799869415745\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 14.8477 - val_loss: 15.8899\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.4785 - val_loss: 7.3135\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.4348 - val_loss: 7.2553\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.9622 - val_loss: 6.1654\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0837 - val_loss: 6.9721\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7605 - val_loss: 10.3269\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5701 - val_loss: 7.5848\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0753 - val_loss: 8.1213\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2817 - val_loss: 6.2217\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4468 - val_loss: 6.2461\n",
      "\n",
      "MAE: 6.246086120605469\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 537\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 14.0151 - val_loss: 9.9399\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.0124 - val_loss: 14.4942\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.9740 - val_loss: 8.1631\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.8462 - val_loss: 13.5731\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.8614 - val_loss: 6.1434\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6246 - val_loss: 7.0567\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4004 - val_loss: 11.6416\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5317 - val_loss: 8.1575\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2347 - val_loss: 5.6074\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2493 - val_loss: 8.3450\n",
      "\n",
      "MAE: 8.345002174377441\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 547\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 16.6988 - val_loss: 6.7863\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.8874 - val_loss: 6.1706\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.5330 - val_loss: 19.8443\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.1047 - val_loss: 12.8270\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5137 - val_loss: 7.8451\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.6421 - val_loss: 6.3307\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7028 - val_loss: 9.1622\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2295 - val_loss: 6.1459\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9341 - val_loss: 11.3038\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2457 - val_loss: 8.1089\n",
      "\n",
      "MAE: 8.108931541442871\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 486\n",
      "activation: relu\n",
      "learning_rate: 0.00907311162127844\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 33.0776 - val_loss: 10.7239\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.7496 - val_loss: 9.5925\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.3285 - val_loss: 6.1397\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0446 - val_loss: 8.2285\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.7042 - val_loss: 12.1761\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1037 - val_loss: 6.5048\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1612 - val_loss: 10.1132\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9325 - val_loss: 4.5568\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3358 - val_loss: 11.2966\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9846 - val_loss: 4.5031\n",
      "\n",
      "MAE: 4.503050804138184\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 495\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 23.7681 - val_loss: 21.1808\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.9870 - val_loss: 14.3640\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3747 - val_loss: 11.1454\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4465 - val_loss: 5.4313\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.0047 - val_loss: 13.8640\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.9558 - val_loss: 5.7694\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6505 - val_loss: 4.8256\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.4749 - val_loss: 6.8555\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5051 - val_loss: 4.5748\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.2611 - val_loss: 5.0927\n",
      "\n",
      "MAE: 5.092681884765625\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 501\n",
      "activation: relu\n",
      "learning_rate: 0.007296558782267342\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 25.7522 - val_loss: 20.5436\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.0398 - val_loss: 6.2836\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0803 - val_loss: 8.9856\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8739 - val_loss: 5.7170\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.2305 - val_loss: 4.5972\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3777 - val_loss: 11.4855\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.2486 - val_loss: 6.9377\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.4326 - val_loss: 7.5004\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3252 - val_loss: 9.6973\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8385 - val_loss: 5.0952\n",
      "\n",
      "MAE: 5.09517765045166\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 500\n",
      "activation: relu\n",
      "learning_rate: 0.008771613557544258\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 32.3920 - val_loss: 18.0069\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.2444 - val_loss: 13.9847\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5292 - val_loss: 5.8305\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.5190 - val_loss: 8.9651\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.5413 - val_loss: 5.8662\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.2683 - val_loss: 8.6472\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.1595 - val_loss: 8.2730\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2716 - val_loss: 5.6859\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3267 - val_loss: 4.7977\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3385 - val_loss: 4.6644\n",
      "\n",
      "MAE: 4.664389133453369\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 491\n",
      "activation: relu\n",
      "learning_rate: 0.008647813312615566\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 40.9809 - val_loss: 9.2736\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.4247 - val_loss: 7.4209\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.8083 - val_loss: 6.3454\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.9330 - val_loss: 5.8036\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.4600 - val_loss: 5.5171\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1985 - val_loss: 5.2631\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9755 - val_loss: 5.1179\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.8306 - val_loss: 5.0492\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7622 - val_loss: 5.0178\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.7153 - val_loss: 4.9375\n",
      "\n",
      "MAE: 4.937502861022949\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 442\n",
      "activation: relu\n",
      "learning_rate: 0.007738101950629535\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 15.0252 - val_loss: 6.8510\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.8036 - val_loss: 11.2616\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3661 - val_loss: 19.9579\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.8888 - val_loss: 11.2259\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.6073 - val_loss: 5.5708\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4449 - val_loss: 4.9340\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.7108 - val_loss: 8.2711\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3735 - val_loss: 7.0025\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8892 - val_loss: 5.2683\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8678 - val_loss: 4.7844\n",
      "\n",
      "MAE: 4.784351825714111\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 493\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 31.3475 - val_loss: 8.3091\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.1569 - val_loss: 7.7473\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.9523 - val_loss: 5.2732\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4959 - val_loss: 4.9821\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7544 - val_loss: 7.7179\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1203 - val_loss: 4.5464\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6507 - val_loss: 4.7254\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4635 - val_loss: 11.3666\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9136 - val_loss: 6.3850\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6709 - val_loss: 7.6005\n",
      "\n",
      "MAE: 7.600541114807129\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 513\n",
      "activation: relu\n",
      "learning_rate: 0.009798670607486057\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 33.9450 - val_loss: 10.2112\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.7117 - val_loss: 8.0991\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.7504 - val_loss: 14.8372\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.4321 - val_loss: 11.8109\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.1701 - val_loss: 12.1039\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8139 - val_loss: 5.0757\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0688 - val_loss: 7.2523\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1627 - val_loss: 4.6655\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.1766 - val_loss: 4.9443\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1255 - val_loss: 6.2227\n",
      "\n",
      "MAE: 6.222738742828369\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 493\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 30.7739 - val_loss: 22.0660\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.6719 - val_loss: 9.6238\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.8516 - val_loss: 5.2754\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.3524 - val_loss: 6.4320\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.2221 - val_loss: 5.9584\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1438 - val_loss: 10.3734\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6194 - val_loss: 8.8685\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2482 - val_loss: 8.1023\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6312 - val_loss: 12.4108\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4708 - val_loss: 7.5277\n",
      "\n",
      "MAE: 7.5277299880981445\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 499\n",
      "activation: relu\n",
      "learning_rate: 0.009120165346018026\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 29.2444 - val_loss: 6.9364\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.9946 - val_loss: 8.0899\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.2744 - val_loss: 11.9969\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.5140 - val_loss: 10.8522\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.5934 - val_loss: 13.0635\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8417 - val_loss: 9.2588\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4614 - val_loss: 11.1506\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6268 - val_loss: 5.2471\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6284 - val_loss: 7.5351\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6351 - val_loss: 8.4122\n",
      "\n",
      "MAE: 8.412162780761719\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 766\n",
      "activation: relu\n",
      "learning_rate: 0.0011310823332354764\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 94.9494 - val_loss: 79.3895\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 53.5357 - val_loss: 13.6009\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 11.3899 - val_loss: 9.7449\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.5687 - val_loss: 9.2703\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.0901 - val_loss: 8.8259\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.6539 - val_loss: 8.4439\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.2320 - val_loss: 8.0243\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.8758 - val_loss: 7.7622\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5388 - val_loss: 7.4517\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.2382 - val_loss: 7.2206\n",
      "\n",
      "MAE: 7.220591068267822\n",
      "\n",
      "\n",
      "num_dense_layers: 10\n",
      "num_dense_nodes: 957\n",
      "activation: relu\n",
      "learning_rate: 0.001\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 12ms/step - loss: 16.6354 - val_loss: 9.6328\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.4765 - val_loss: 7.4646\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 10.6337 - val_loss: 8.7148\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.7780 - val_loss: 8.4304\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 9.3088 - val_loss: 13.0807\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.7777 - val_loss: 13.1993\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.5545 - val_loss: 8.7528\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 7.1063 - val_loss: 8.9250\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.8711 - val_loss: 10.8611\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.3948 - val_loss: 13.8804\n",
      "\n",
      "MAE: 13.880359649658203\n",
      "\n",
      "\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 19.7416 - val_loss: 7.2770\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7088 - val_loss: 8.9433\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1957 - val_loss: 5.8823\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9752 - val_loss: 5.2292\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9290 - val_loss: 6.2207\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7132 - val_loss: 7.5094\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7160 - val_loss: 5.0692\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7585 - val_loss: 5.5397\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.5473 - val_loss: 6.6283\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.4347 - val_loss: 6.7300\n",
      "\n",
      "MAE: 6.72999906539917\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 45.3496 - val_loss: 9.4561\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.0993 - val_loss: 8.8668\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.3960 - val_loss: 7.9657\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3474 - val_loss: 6.7396\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.2037 - val_loss: 5.8052\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5825 - val_loss: 5.5207\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2295 - val_loss: 5.2369\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0283 - val_loss: 5.0510\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8679 - val_loss: 4.9239\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7484 - val_loss: 4.8421\n",
      "\n",
      "MAE: 4.842132568359375\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 24.4937 - val_loss: 7.5859\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7730 - val_loss: 6.2690\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5431 - val_loss: 5.5525\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0620 - val_loss: 5.3956\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8841 - val_loss: 5.4039\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8680 - val_loss: 5.4184\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9026 - val_loss: 5.5067\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9272 - val_loss: 5.4600\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8760 - val_loss: 5.4600\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8099 - val_loss: 5.3957\n",
      "\n",
      "MAE: 5.395663261413574\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: relu\n",
      "learning_rate: 0.0060782701786613125\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 40.4264 - val_loss: 9.2395\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3355 - val_loss: 7.3318\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.7513 - val_loss: 6.3290\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.8598 - val_loss: 5.7802\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.4100 - val_loss: 5.5187\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1339 - val_loss: 5.2557\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9404 - val_loss: 5.1545\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8467 - val_loss: 5.0481\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7311 - val_loss: 5.0130\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.6977 - val_loss: 4.9453\n",
      "\n",
      "MAE: 4.945282459259033\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.006718802574525209\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 73.4513 - val_loss: 10.6821\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.8155 - val_loss: 9.1682\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.7402 - val_loss: 8.2000\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.9154 - val_loss: 7.5016\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.2371 - val_loss: 7.0135\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.6560 - val_loss: 6.6556\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.2320 - val_loss: 6.4157\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.8857 - val_loss: 6.1663\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6368 - val_loss: 5.9789\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4587 - val_loss: 5.8619\n",
      "\n",
      "MAE: 5.861935138702393\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 45.1738 - val_loss: 9.4522\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.0869 - val_loss: 8.8552\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3726 - val_loss: 7.9364\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3108 - val_loss: 6.7436\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1921 - val_loss: 5.7839\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5703 - val_loss: 5.4898\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2417 - val_loss: 5.2259\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0559 - val_loss: 5.0886\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8434 - val_loss: 4.9211\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7414 - val_loss: 4.8254\n",
      "\n",
      "MAE: 4.8254170417785645\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 24.4654 - val_loss: 7.5636\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.7945 - val_loss: 6.2249\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4714 - val_loss: 5.5397\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0219 - val_loss: 5.3703\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8230 - val_loss: 5.3494\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.8431 - val_loss: 5.3625\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8520 - val_loss: 5.5495\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0912 - val_loss: 5.4833\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8547 - val_loss: 5.5050\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9151 - val_loss: 5.4574\n",
      "\n",
      "MAE: 5.4574198722839355\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 5ms/step - loss: 45.2984 - val_loss: 9.4531\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.0943 - val_loss: 8.8694\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3932 - val_loss: 7.9586\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3377 - val_loss: 6.7304\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.2030 - val_loss: 5.8124\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 6.5681 - val_loss: 5.4937\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.2336 - val_loss: 5.2193\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.0564 - val_loss: 5.1262\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8487 - val_loss: 4.9219\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.7530 - val_loss: 4.8306\n",
      "\n",
      "MAE: 4.830576419830322\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 5ms/step - loss: 45.1797 - val_loss: 9.4539\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 10.0934 - val_loss: 8.8574\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 9.3792 - val_loss: 7.9402\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3277 - val_loss: 6.7573\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.1895 - val_loss: 5.7813\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5561 - val_loss: 5.5275\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.2211 - val_loss: 5.2194\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0199 - val_loss: 5.0429\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8806 - val_loss: 5.1001\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6999 - val_loss: 4.8244\n",
      "\n",
      "MAE: 4.824390888214111\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 476\n",
      "activation: relu\n",
      "learning_rate: 0.009024431138539294\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 26.3695 - val_loss: 6.7221\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.4779 - val_loss: 5.0499\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5045 - val_loss: 11.4403\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0523 - val_loss: 9.2646\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.3332 - val_loss: 6.9618\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8612 - val_loss: 6.9820\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6808 - val_loss: 6.3025\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3351 - val_loss: 8.6147\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1968 - val_loss: 8.4023\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6126 - val_loss: 5.2808\n",
      "\n",
      "MAE: 5.28079080581665\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 505\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 34.9674 - val_loss: 16.6810\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.9594 - val_loss: 5.2938\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.1370 - val_loss: 10.9404\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3226 - val_loss: 15.5458\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.0994 - val_loss: 8.5955\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.3598 - val_loss: 9.8400\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0081 - val_loss: 12.9665\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3608 - val_loss: 11.5695\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.0773 - val_loss: 6.5277\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0851 - val_loss: 7.9120\n",
      "\n",
      "MAE: 7.911991119384766\n",
      "\n",
      "\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 497\n",
      "activation: relu\n",
      "learning_rate: 0.0086637836154141\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 17.3202 - val_loss: 8.0615\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.2885 - val_loss: 8.1579\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.8333 - val_loss: 12.5674\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.7672 - val_loss: 6.3796\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3129 - val_loss: 6.2690\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6861 - val_loss: 12.4114\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.1272 - val_loss: 8.3743\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9410 - val_loss: 5.4676\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6922 - val_loss: 6.2775\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8058 - val_loss: 5.1833\n",
      "\n",
      "MAE: 5.183260917663574\n",
      "\n",
      "\n",
      "num_dense_layers: 8\n",
      "num_dense_nodes: 494\n",
      "activation: relu\n",
      "learning_rate: 0.009600856893902235\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 10ms/step - loss: 41.7120 - val_loss: 18.8416\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.9629 - val_loss: 5.5704\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.0688 - val_loss: 8.9387\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 8.0335 - val_loss: 4.8781\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.9442 - val_loss: 5.8369\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.5351 - val_loss: 5.4468\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.9693 - val_loss: 7.9741\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6012 - val_loss: 6.2242\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.8745 - val_loss: 5.1848\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3048 - val_loss: 5.5407\n",
      "\n",
      "MAE: 5.540698528289795\n",
      "\n",
      "\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 489\n",
      "activation: relu\n",
      "learning_rate: 0.00880407543194877\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 6ms/step - loss: 27.9268 - val_loss: 17.3148\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.1710 - val_loss: 11.1368\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8860 - val_loss: 7.2660\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.9674 - val_loss: 5.3016\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4982 - val_loss: 4.6078\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0841 - val_loss: 4.9122\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3329 - val_loss: 7.0568\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7768 - val_loss: 5.4412\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1732 - val_loss: 9.1829\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.6394 - val_loss: 9.3209\n",
      "\n",
      "MAE: 9.320907592773438\n",
      "\n",
      "\n",
      "num_dense_layers: 8\n",
      "num_dense_nodes: 505\n",
      "activation: relu\n",
      "learning_rate: 0.008719461416068514\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 10ms/step - loss: 40.8619 - val_loss: 8.2987\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.9294 - val_loss: 5.5812\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.7343 - val_loss: 7.2543\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.2777 - val_loss: 17.4036\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5865 - val_loss: 11.5099\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 2s 16ms/step - loss: 6.2609 - val_loss: 7.8503\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.9703 - val_loss: 6.1309\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.3004 - val_loss: 7.4939\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5938 - val_loss: 9.1309\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.6341 - val_loss: 8.3162\n",
      "\n",
      "MAE: 8.316183090209961\n",
      "\n",
      "\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 504\n",
      "activation: relu\n",
      "learning_rate: 0.00854964214596309\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 26.5976 - val_loss: 6.5881\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.5848 - val_loss: 17.4278\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 12ms/step - loss: 7.8100 - val_loss: 10.1649\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 7.2540 - val_loss: 7.8481\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.4172 - val_loss: 6.6502\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9403 - val_loss: 5.1592\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7836 - val_loss: 6.0594\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1766 - val_loss: 6.5774\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4064 - val_loss: 4.5441\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1290 - val_loss: 6.5316\n",
      "\n",
      "MAE: 6.531563758850098\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 498\n",
      "activation: relu\n",
      "learning_rate: 0.009999724728767423\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 31.6665 - val_loss: 11.8825\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.7477 - val_loss: 12.8111\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.5997 - val_loss: 7.3283\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.5195 - val_loss: 9.1638\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6895 - val_loss: 5.1803\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.5529 - val_loss: 4.5565\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.1325 - val_loss: 4.6028\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.1455 - val_loss: 7.5142\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.9304 - val_loss: 4.3733\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7607 - val_loss: 7.0185\n",
      "\n",
      "MAE: 7.018482685089111\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 508\n",
      "activation: relu\n",
      "learning_rate: 0.009541698838128033\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 31.1642 - val_loss: 17.3821\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 10.4961 - val_loss: 18.1960\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.3287 - val_loss: 9.9442\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.8270 - val_loss: 6.4699\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.6815 - val_loss: 12.2818\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 6.4544 - val_loss: 4.5266\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 8.4975 - val_loss: 8.1365\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.2565 - val_loss: 16.2799\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.0928 - val_loss: 6.2545\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.9131 - val_loss: 4.7423\n",
      "\n",
      "MAE: 4.742259502410889\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 7ms/step - loss: 45.2049 - val_loss: 9.4620\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1011 - val_loss: 8.8634\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.4005 - val_loss: 7.9680\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3505 - val_loss: 6.7537\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.2107 - val_loss: 5.7936\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5798 - val_loss: 5.4964\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2480 - val_loss: 5.2231\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0382 - val_loss: 5.0453\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8690 - val_loss: 4.9318\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7305 - val_loss: 4.8260\n",
      "\n",
      "MAE: 4.826025485992432\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 636\n",
      "activation: tanh\n",
      "learning_rate: 0.00812850422807334\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 30.1483 - val_loss: 8.3963\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.5621 - val_loss: 6.8613\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.2013 - val_loss: 5.9194\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5003 - val_loss: 6.3184\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2528 - val_loss: 6.0159\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0302 - val_loss: 5.6749\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8622 - val_loss: 5.5592\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7259 - val_loss: 5.2620\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6180 - val_loss: 5.3332\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.6017 - val_loss: 5.4653\n",
      "\n",
      "MAE: 5.465292453765869\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 502\n",
      "activation: relu\n",
      "learning_rate: 0.008853605715982732\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 10ms/step - loss: 29.8860 - val_loss: 21.9654\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.4095 - val_loss: 6.5478\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 8.3921 - val_loss: 15.0290\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4785 - val_loss: 4.9987\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.1125 - val_loss: 11.7877\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5979 - val_loss: 15.2392\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.9151 - val_loss: 6.8572\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.0608 - val_loss: 5.8033\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9916 - val_loss: 4.5338\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5035 - val_loss: 6.8681\n",
      "\n",
      "MAE: 6.868056297302246\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 649\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 27.2238 - val_loss: 8.8447\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.1595 - val_loss: 7.8689\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.3544 - val_loss: 8.2427\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.8804 - val_loss: 11.3518\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.5777 - val_loss: 4.8310\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3895 - val_loss: 4.6957\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4631 - val_loss: 8.8809\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.1891 - val_loss: 10.0871\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3154 - val_loss: 7.7161\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7093 - val_loss: 6.4009\n",
      "\n",
      "MAE: 6.40091609954834\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 498\n",
      "activation: relu\n",
      "learning_rate: 0.008708686845874076\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 29.8658 - val_loss: 17.8930\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.1761 - val_loss: 11.0916\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.8882 - val_loss: 5.1148\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.8434 - val_loss: 11.5901\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.5070 - val_loss: 8.9274\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.7995 - val_loss: 8.8390\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.0839 - val_loss: 11.5204\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.6924 - val_loss: 8.0166\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.9072 - val_loss: 5.3605\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.2474 - val_loss: 4.8505\n",
      "\n",
      "MAE: 4.850472927093506\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 502\n",
      "activation: tanh\n",
      "learning_rate: 0.00857027478404109\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 31.5783 - val_loss: 8.5950\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.7535 - val_loss: 6.8269\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3516 - val_loss: 6.0067\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5962 - val_loss: 5.7693\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2173 - val_loss: 5.6580\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0406 - val_loss: 5.5615\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8865 - val_loss: 5.5652\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7899 - val_loss: 5.4183\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6893 - val_loss: 5.4386\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6522 - val_loss: 5.5816\n",
      "\n",
      "MAE: 5.5815510749816895\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 503\n",
      "activation: tanh\n",
      "learning_rate: 0.009496887770115568\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 17.2591 - val_loss: 9.4973\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 10.2065 - val_loss: 9.5671\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 10.2252 - val_loss: 9.5925\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.2624 - val_loss: 9.5191\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 10.2665 - val_loss: 9.5334\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 10.2739 - val_loss: 9.5780\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.2828 - val_loss: 9.5634\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.2821 - val_loss: 9.5646\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.2809 - val_loss: 9.6150\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.3243 - val_loss: 9.5372\n",
      "\n",
      "MAE: 9.537221908569336\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 612\n",
      "activation: relu\n",
      "learning_rate: 0.009952411167607655\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 20.8321 - val_loss: 6.1779\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.6201 - val_loss: 6.0233\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8936 - val_loss: 9.4633\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8305 - val_loss: 9.7605\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1559 - val_loss: 9.3177\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1975 - val_loss: 6.1877\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.4196 - val_loss: 6.0903\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6861 - val_loss: 10.9378\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7226 - val_loss: 6.6593\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1240 - val_loss: 5.4509\n",
      "\n",
      "MAE: 5.450928688049316\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 490\n",
      "activation: relu\n",
      "learning_rate: 0.009501543370998736\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 27.2303 - val_loss: 16.2287\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.6597 - val_loss: 19.7808\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.0890 - val_loss: 5.0769\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.0033 - val_loss: 8.2669\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.5290 - val_loss: 5.3891\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.5249 - val_loss: 9.0976\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.1804 - val_loss: 4.6278\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0832 - val_loss: 10.5411\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.8324 - val_loss: 8.9409\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.8298 - val_loss: 12.1645\n",
      "\n",
      "MAE: 12.164539337158203\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 446\n",
      "activation: relu\n",
      "learning_rate: 0.00765589858530943\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 17.3456 - val_loss: 6.1187\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.4929 - val_loss: 10.6748\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.8524 - val_loss: 9.4066\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.0658 - val_loss: 7.2427\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7354 - val_loss: 6.5535\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.9909 - val_loss: 4.8750\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0586 - val_loss: 5.0771\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2435 - val_loss: 5.5070\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7506 - val_loss: 5.9349\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.0712 - val_loss: 7.8091\n",
      "\n",
      "MAE: 7.809116363525391\n",
      "\n",
      "\n",
      "num_dense_layers: 4\n",
      "num_dense_nodes: 439\n",
      "activation: relu\n",
      "learning_rate: 0.007795803028491356\n",
      "kernel: glorot_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 14.3641 - val_loss: 8.4510\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1226 - val_loss: 10.6659\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.6593 - val_loss: 12.0221\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.0597 - val_loss: 5.9094\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.3986 - val_loss: 5.4578\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 6.5049 - val_loss: 5.2833\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.4773 - val_loss: 6.9461\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3821 - val_loss: 8.3944\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.2842 - val_loss: 9.1321\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9675 - val_loss: 6.5308\n",
      "\n",
      "MAE: 6.530775547027588\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 961\n",
      "activation: tanh\n",
      "learning_rate: 0.009922234120011423\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 24.7583 - val_loss: 7.6300\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8282 - val_loss: 6.3449\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5081 - val_loss: 5.5459\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0576 - val_loss: 5.3876\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7716 - val_loss: 5.3218\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9018 - val_loss: 5.4076\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9679 - val_loss: 5.5135\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9035 - val_loss: 5.4621\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8162 - val_loss: 5.4251\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8207 - val_loss: 5.3670\n",
      "\n",
      "MAE: 5.367005348205566\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 485\n",
      "activation: relu\n",
      "learning_rate: 0.009010806245047995\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 10ms/step - loss: 30.7136 - val_loss: 18.8664\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 8.4771 - val_loss: 5.9083\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.1841 - val_loss: 5.4004\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 8.4382 - val_loss: 4.8721\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.2300 - val_loss: 16.5195\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.0499 - val_loss: 7.1683\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.7803 - val_loss: 7.2952\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.6592 - val_loss: 8.1026\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8806 - val_loss: 7.8683\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0257 - val_loss: 9.5208\n",
      "\n",
      "MAE: 9.520783424377441\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 485\n",
      "activation: relu\n",
      "learning_rate: 0.009119536720662003\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 28.6938 - val_loss: 9.3795\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.1157 - val_loss: 6.6601\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.5104 - val_loss: 4.9022\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4594 - val_loss: 5.3624\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.4302 - val_loss: 6.3077\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7745 - val_loss: 4.6535\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.6484 - val_loss: 9.0772\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.5580 - val_loss: 6.5069\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5175 - val_loss: 11.7279\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 6.9079 - val_loss: 6.9190\n",
      "\n",
      "MAE: 6.9190497398376465\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.0066580875187490516\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 71.3491 - val_loss: 10.0340\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.7043 - val_loss: 9.0777\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.6502 - val_loss: 8.0990\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.8372 - val_loss: 7.4159\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.1292 - val_loss: 6.9388\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.5571 - val_loss: 6.6144\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.1353 - val_loss: 6.3743\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.8200 - val_loss: 6.1475\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5772 - val_loss: 5.9469\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.4188 - val_loss: 5.8043\n",
      "\n",
      "MAE: 5.804291248321533\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 6ms/step - loss: 45.3437 - val_loss: 9.4549\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.0970 - val_loss: 8.8679\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3914 - val_loss: 7.9611\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3388 - val_loss: 6.7589\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.1931 - val_loss: 5.8096\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5535 - val_loss: 5.4858\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2378 - val_loss: 5.2125\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0307 - val_loss: 5.0551\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8553 - val_loss: 4.9437\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7138 - val_loss: 4.8409\n",
      "\n",
      "MAE: 4.840862274169922\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 7ms/step - loss: 24.4531 - val_loss: 7.5766\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7414 - val_loss: 6.3146\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4945 - val_loss: 5.5519\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9815 - val_loss: 5.4129\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.8220 - val_loss: 5.5126\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0012 - val_loss: 5.4383\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0928 - val_loss: 5.4239\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9107 - val_loss: 5.4221\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8054 - val_loss: 5.3433\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7778 - val_loss: 5.2957\n",
      "\n",
      "MAE: 5.29574728012085\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 511\n",
      "activation: relu\n",
      "learning_rate: 0.0094786249729981\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 27.9406 - val_loss: 14.4170\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.3092 - val_loss: 6.4136\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 9.6345 - val_loss: 11.6010\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 7.3710 - val_loss: 4.7793\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.6022 - val_loss: 6.9952\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 7.3923 - val_loss: 7.3678\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 6.7977 - val_loss: 4.5393\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7320 - val_loss: 10.5506\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3419 - val_loss: 5.2969\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.0459 - val_loss: 8.4310\n",
      "\n",
      "MAE: 8.431004524230957\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.007243347235685481\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 28.8249 - val_loss: 8.3332\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3160 - val_loss: 6.5720\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.9182 - val_loss: 6.2039\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.3680 - val_loss: 5.7118\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0754 - val_loss: 5.7579\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9833 - val_loss: 5.5731\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8219 - val_loss: 5.3667\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.7351 - val_loss: 5.4061\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.6651 - val_loss: 5.3120\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.6296 - val_loss: 5.3718\n",
      "\n",
      "MAE: 5.371760845184326\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 54.2229 - val_loss: 9.8597\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1513 - val_loss: 8.2441\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.7963 - val_loss: 7.2706\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.7988 - val_loss: 6.6647\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1098 - val_loss: 6.1520\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6842 - val_loss: 5.8594\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4038 - val_loss: 5.6718\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2220 - val_loss: 5.4718\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0961 - val_loss: 5.4297\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9400 - val_loss: 5.2553\n",
      "\n",
      "MAE: 5.255328178405762\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 9ms/step - loss: 24.5249 - val_loss: 7.6051\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.7689 - val_loss: 6.3373\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 6.5067 - val_loss: 5.5532\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 6.0059 - val_loss: 5.3639\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8282 - val_loss: 5.3562\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9057 - val_loss: 5.4355\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.8526 - val_loss: 5.5168\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9304 - val_loss: 5.7107\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.9782 - val_loss: 5.4655\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8498 - val_loss: 5.4677\n",
      "\n",
      "MAE: 5.467735290527344\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.007160012539207295\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 56.5284 - val_loss: 10.2907\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.2823 - val_loss: 9.1485\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.7929 - val_loss: 8.6378\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.1953 - val_loss: 7.8594\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3680 - val_loss: 6.8813\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.4680 - val_loss: 6.2287\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.8142 - val_loss: 5.8861\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4606 - val_loss: 5.6033\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2625 - val_loss: 5.3974\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1113 - val_loss: 5.2923\n",
      "\n",
      "MAE: 5.292349338531494\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 53.6504 - val_loss: 9.8284\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1320 - val_loss: 8.2318\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.8028 - val_loss: 7.2820\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.8116 - val_loss: 6.6454\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1421 - val_loss: 6.1518\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.7173 - val_loss: 5.8470\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4434 - val_loss: 5.6999\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2301 - val_loss: 5.4793\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.1159 - val_loss: 5.3593\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.9945 - val_loss: 5.2674\n",
      "\n",
      "MAE: 5.267436981201172\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 6ms/step - loss: 45.0937 - val_loss: 9.4557\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.0958 - val_loss: 8.8561\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.3946 - val_loss: 7.9494\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3330 - val_loss: 6.7131\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1943 - val_loss: 5.8058\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5798 - val_loss: 5.5307\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.2326 - val_loss: 5.2064\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.0310 - val_loss: 5.0629\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8607 - val_loss: 4.9555\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7177 - val_loss: 4.8296\n",
      "\n",
      "MAE: 4.8295793533325195\n",
      "\n",
      "\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 504\n",
      "activation: relu\n",
      "learning_rate: 0.009511838360254904\n",
      "kernel: he_normal\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 2s 9ms/step - loss: 27.7253 - val_loss: 16.0817\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.6776 - val_loss: 6.7843\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 11.2802 - val_loss: 5.5484\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.2314 - val_loss: 12.6027\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6726 - val_loss: 8.5062\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 8.2567 - val_loss: 9.3419\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.5964 - val_loss: 12.0085\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.9117 - val_loss: 5.8806\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.3750 - val_loss: 7.8035\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.6004 - val_loss: 6.6197\n",
      "\n",
      "MAE: 6.619671821594238\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.006777077450273771\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 68.7074 - val_loss: 10.9417\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.7003 - val_loss: 8.9926\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.5407 - val_loss: 7.9871\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.6929 - val_loss: 7.2856\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9704 - val_loss: 6.8469\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3993 - val_loss: 6.4838\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.9724 - val_loss: 6.2521\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.6661 - val_loss: 6.0029\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.4581 - val_loss: 5.8595\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3125 - val_loss: 5.7461\n",
      "\n",
      "MAE: 5.74611759185791\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 6ms/step - loss: 44.9475 - val_loss: 9.4539\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 10.0939 - val_loss: 8.8527\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3802 - val_loss: 7.9267\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 8.3073 - val_loss: 6.7421\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.1746 - val_loss: 5.7812\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.5594 - val_loss: 5.5600\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2369 - val_loss: 5.2070\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.0279 - val_loss: 5.0436\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 5.8565 - val_loss: 4.9518\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7007 - val_loss: 4.8304\n",
      "\n",
      "MAE: 4.830379962921143\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 7ms/step - loss: 44.8934 - val_loss: 9.4411\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.0777 - val_loss: 8.8318\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3503 - val_loss: 7.9018\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.2840 - val_loss: 6.6975\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1701 - val_loss: 5.7852\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.5566 - val_loss: 5.4762\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2403 - val_loss: 5.2126\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0340 - val_loss: 5.0477\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8621 - val_loss: 4.9178\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.7184 - val_loss: 4.8315\n",
      "\n",
      "MAE: 4.831466197967529\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 968\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 8ms/step - loss: 24.5463 - val_loss: 7.5794\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.8073 - val_loss: 6.3190\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.5691 - val_loss: 5.5518\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.0710 - val_loss: 5.3427\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7646 - val_loss: 5.3096\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.8253 - val_loss: 5.3204\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7744 - val_loss: 5.4639\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9857 - val_loss: 5.5991\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9065 - val_loss: 5.5217\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.9202 - val_loss: 5.4250\n",
      "\n",
      "MAE: 5.425029754638672\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.007128537211792584\n",
      "kernel: he_uniform\n",
      "\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 56.5756 - val_loss: 10.2577\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.2846 - val_loss: 9.1531\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.7950 - val_loss: 8.6411\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.1940 - val_loss: 7.8649\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3614 - val_loss: 6.8767\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.4677 - val_loss: 6.2304\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.8184 - val_loss: 5.8622\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.4663 - val_loss: 5.5972\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 6.2606 - val_loss: 5.3873\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1432 - val_loss: 5.2684\n",
      "\n",
      "MAE: 5.2684006690979\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: relu\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 6ms/step - loss: 55.0697 - val_loss: 9.9308\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 10.1873 - val_loss: 8.2678\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.8256 - val_loss: 7.2964\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.8076 - val_loss: 6.6562\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.1170 - val_loss: 6.1988\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.6769 - val_loss: 5.8467\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.3892 - val_loss: 5.6927\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.1985 - val_loss: 5.4648\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0949 - val_loss: 5.3318\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.9675 - val_loss: 5.3140\n",
      "\n",
      "MAE: 5.314014911651611\n",
      "\n",
      "\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 128\n",
      "activation: tanh\n",
      "learning_rate: 0.01\n",
      "kernel: glorot_normal\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yihim\\anaconda3\\envs\\mldl\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 1s 6ms/step - loss: 45.0665 - val_loss: 9.4457\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 10.0901 - val_loss: 8.8528\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.3684 - val_loss: 7.9294\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.3101 - val_loss: 6.7426\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.1800 - val_loss: 5.7908\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 6.5806 - val_loss: 5.5442\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.2337 - val_loss: 5.2196\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 6.0315 - val_loss: 5.0518\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.8555 - val_loss: 4.9322\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.7614 - val_loss: 4.9158\n",
      "\n",
      "MAE: 4.9157795906066895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp = gp_minimize(objective,\n",
    "                 param_grid,\n",
    "                 n_calls=100,\n",
    "                 n_jobs=-1,\n",
    "                 x0=initial_parameters,\n",
    "                 acq_func=\"EI\",\n",
    "                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "1c5a0f70-4b07-4f4a-a2ef-68ee4da99e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 4.464505195617676\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best score: {gp.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "55967c89-9ad7-4b1b-94e5-d555a263eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "num_dense_layers: 7\n",
      "num_dense_nodes: 506\n",
      "activation: relu\n",
      "learning_rate: 0.009480\n",
      "kernel: he_normal\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\\nnum_dense_layers: %d\\nnum_dense_nodes: %d\\nactivation: %s\\nlearning_rate: %.6f\\nkernel: %s\" % (gp.x[0], gp.x[1], gp.x[2], gp.x[3], gp.x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "721b72ab-8137-4094-83f4-3a1804ce2c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 89/106 [========================>.....] - ETA: 0s - loss: 62.3301INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 2s 11ms/step - loss: 57.3830 - val_loss: 23.6285\n",
      "Epoch 2/20\n",
      " 83/106 [======================>.......] - ETA: 0s - loss: 13.5513INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 12.7663 - val_loss: 9.5229\n",
      "Epoch 3/20\n",
      " 86/106 [=======================>......] - ETA: 0s - loss: 10.2488INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.1498 - val_loss: 9.4929\n",
      "Epoch 4/20\n",
      " 84/106 [======================>.......] - ETA: 0s - loss: 9.6351INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.3618 - val_loss: 7.3478\n",
      "Epoch 5/20\n",
      " 84/106 [======================>.......] - ETA: 0s - loss: 7.1586INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0218 - val_loss: 5.2788\n",
      "Epoch 6/20\n",
      "104/106 [============================>.] - ETA: 0s - loss: 5.6838INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.6750 - val_loss: 4.6384\n",
      "Epoch 7/20\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 5.3373INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.2866 - val_loss: 4.5903\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.1444 - val_loss: 4.6105\n",
      "Epoch 9/20\n",
      " 92/106 [=========================>....] - ETA: 0s - loss: 5.1160INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.0518 - val_loss: 4.4960\n",
      "Epoch 10/20\n",
      " 87/106 [=======================>......] - ETA: 0s - loss: 4.9891INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.9922 - val_loss: 4.3809\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.9396 - val_loss: 4.3907\n",
      "Epoch 12/20\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 4.9500INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_3_bo\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.9148 - val_loss: 4.3212\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8804 - val_loss: 4.4145\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8506 - val_loss: 4.3338\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8247 - val_loss: 4.3309\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8193 - val_loss: 4.3713\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8011 - val_loss: 4.3991\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7817 - val_loss: 4.3533\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8166 - val_loss: 4.3357\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7860 - val_loss: 4.3446\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(376,), dtype=tf.float32),\n",
    "    layers.Dense(512, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_3_bo\")\n",
    "\n",
    "model_3.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_3_history = model_3.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=20,\n",
    "                              callbacks=[tensorboard(model_3.name),\n",
    "                                         checkpoint(model_3.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db7ffa3b-8304-4c01-be43-d171e5b318c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417449969674033"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds = model_3.predict(val_dataset_1)\n",
    "model_3_r2 = r2_score(val_target, tf.squeeze(model_3_preds))\n",
    "model_3_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d01eea3d-780e-44f2-b21c-18914557744b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108.21, 105.82, 108.19,  94.62, 110.46,  88.98, 108.84, 109.93,\n",
       "       104.89,  99.65])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8570e1d9-9e0b-4d82-ae95-53e4ecb81c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([107.70192 ,  90.692986, 108.712105,  91.97529 , 106.38257 ,\n",
       "        90.71417 ,  90.16152 , 108.030304,  89.67147 , 104.088005],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(model_3_preds)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4581717d-9188-4545-87e2-3b271b4a5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb6f3727-a649-4e06-b25a-9aee862f24ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b87e8f6e9cfc9d3e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b87e8f6e9cfc9d3e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8090;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model_logs/greener_manufacturing --port 8090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a4ed6ee-c583-4f9f-8a97-8e361c385822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 95/106 [=========================>....] - ETA: 0s - loss: 50.0554INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 46.4458 - val_loss: 10.2204\n",
      "Epoch 2/20\n",
      " 88/106 [=======================>......] - ETA: 0s - loss: 10.3242INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.2342 - val_loss: 9.5065\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 9.9587 INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.9587 - val_loss: 8.5510\n",
      "Epoch 4/20\n",
      " 90/106 [========================>.....] - ETA: 0s - loss: 8.3090INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.1124 - val_loss: 6.1744\n",
      "Epoch 5/20\n",
      "104/106 [============================>.] - ETA: 0s - loss: 6.1139INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.1057 - val_loss: 4.7509\n",
      "Epoch 6/20\n",
      "102/106 [===========================>..] - ETA: 0s - loss: 5.4097INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.3885 - val_loss: 4.6832\n",
      "Epoch 7/20\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 5.2388INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.1990 - val_loss: 4.6101\n",
      "Epoch 8/20\n",
      " 92/106 [=========================>....] - ETA: 0s - loss: 5.1650INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.0954 - val_loss: 4.5467\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.0105 - val_loss: 4.5565\n",
      "Epoch 10/20\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 5.0015INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 4.9776 - val_loss: 4.5321\n",
      "Epoch 11/20\n",
      " 95/106 [=========================>....] - ETA: 0s - loss: 4.9653INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 4.9291 - val_loss: 4.5274\n",
      "Epoch 12/20\n",
      " 94/106 [=========================>....] - ETA: 0s - loss: 4.9504INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.9098 - val_loss: 4.4430\n",
      "Epoch 13/20\n",
      " 90/106 [========================>.....] - ETA: 0s - loss: 4.9012INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.8832 - val_loss: 4.4402\n",
      "Epoch 14/20\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 4.9329INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 4.8774 - val_loss: 4.4356\n",
      "Epoch 15/20\n",
      "104/106 [============================>.] - ETA: 0s - loss: 4.8884INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.8791 - val_loss: 4.3845\n",
      "Epoch 16/20\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 4.9350INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.8748 - val_loss: 4.3747\n",
      "Epoch 17/20\n",
      " 95/106 [=========================>....] - ETA: 0s - loss: 4.9134INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 4.8670 - val_loss: 4.3485\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8480 - val_loss: 4.3604\n",
      "Epoch 19/20\n",
      "102/106 [===========================>..] - ETA: 0s - loss: 4.8831INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_4_bo_2\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.8467 - val_loss: 4.3102\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7627 - val_loss: 4.3305\n"
     ]
    }
   ],
   "source": [
    "model_4 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(376,), dtype=tf.float32),\n",
    "    layers.Dense(640, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_4_bo_2\")\n",
    "\n",
    "model_4.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_4_history = model_4.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=20,\n",
    "                              callbacks=[tensorboard(model_4.name),\n",
    "                                         checkpoint(model_4.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e3be3069-3a06-402d-9699-520a4b4de005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480955758204163"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = model_4.predict(val_dataset_1)\n",
    "model_4_r2 = r2_score(val_target, tf.squeeze(model_4_preds))\n",
    "model_4_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e52fb08c-01a9-4dbd-a863-846ea6724962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4806961559984243"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_train_preds = model_4.predict(train_dataset_1)\n",
    "model_4_train_r2 = r2_score(train_target, tf.squeeze(model_4_train_preds))\n",
    "model_4_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1dc05743-ba92-4e33-9467-3af676155dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8090 (pid 32896), started 0:12:03 ago. (Use '!kill 32896' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-307677de4b295136\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-307677de4b295136\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8090;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model_logs/greener_manufacturing --port 8090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5be7c71f-017e-439f-a5d6-2566ca8b2854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0  X1  X2  X3  X4  X5  X6  X8  ...  X375  X376  X377  X378  \\\n",
       "0   0  130.81  33  24  18   1   4  25  10  15  ...     0     0     1     0   \n",
       "1   6   88.53  33  22  20   5   4  29  12  15  ...     1     0     0     0   \n",
       "2   7   76.26  21  25  35   3   4  28  10  24  ...     0     0     0     0   \n",
       "3   9   80.62  21  22  35   6   4  28  12   5  ...     0     0     0     0   \n",
       "4  13   78.02  21  24  35   6   4  13   4  14  ...     0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "307c6e09-264d-43ae-9aab-76f9fc7fffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "87f99c91-c17c-4807-922d-e73b5322b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8'], dtype='<U2')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_keys = cat_dict.keys()\n",
    "cat_keys = np.array(list(cat_keys))\n",
    "cat_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5340d6fb-3388-4ace-8192-3f018d6284c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 563)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = ColumnTransformer(transformers=[(\"one_hot\", OneHotEncoder(), cat_keys)], remainder=\"passthrough\")\n",
    "\n",
    "train_data_one_hot_features = ct.fit_transform(train_data.drop([\"ID\", \"y\"], axis = 1))\n",
    "train_data_one_hot_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "14ca80a8-935f-4f9a-8226-a574845d8697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 376)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "610f7dbc-7b79-44f8-938c-b50d7ce194b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 842)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_hot_features = train_data_one_hot_features[:split_size]\n",
    "val_one_hot_features = train_data_one_hot_features[split_size:]\n",
    "len(train_one_hot_features), len(val_one_hot_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8cc765d1-cf2b-40ac-a176-5d036f27a47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 842)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_target), len(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8888686b-5fb4-4ba9-bfa7-bab07108d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_2 = tf.data.Dataset.from_tensor_slices(tf.cast(train_one_hot_features, dtype=tf.float32))\n",
    "train_target_2 = tf.data.Dataset.from_tensor_slices(tf.cast(train_target, dtype=tf.float32))\n",
    "train_dataset_2 = tf.data.Dataset.zip((train_features_2, train_target_2)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_features_2 = tf.data.Dataset.from_tensor_slices(tf.cast(val_one_hot_features, dtype=tf.float32))\n",
    "val_target_2 = tf.data.Dataset.from_tensor_slices(tf.cast(val_target, dtype=tf.float32))\n",
    "val_dataset_2 = tf.data.Dataset.zip((val_features_2, val_target_2)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f596e253-8ce7-4744-8fc1-a67cf8e18522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_hot_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d039605d-4378-49c2-97a4-9a33d10005f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/106 [============================>.] - ETA: 0s - loss: 52.3945INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 51.6521 - val_loss: 15.7320\n",
      "Epoch 2/20\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 10.9457INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.8508 - val_loss: 9.4362\n",
      "Epoch 3/20\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 9.8350 INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.7502 - val_loss: 7.6901\n",
      "Epoch 4/20\n",
      " 85/106 [=======================>......] - ETA: 0s - loss: 6.9857INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 6.7546 - val_loss: 4.6482\n",
      "Epoch 5/20\n",
      "105/106 [============================>.] - ETA: 0s - loss: 5.2960INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.2982 - val_loss: 4.4954\n",
      "Epoch 6/20\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 5.1079INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.0545 - val_loss: 4.4774\n",
      "Epoch 7/20\n",
      "104/106 [============================>.] - ETA: 0s - loss: 4.9588INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.9472 - val_loss: 4.4114\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8907 - val_loss: 4.4516\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 4.8455 - val_loss: 4.4388\n",
      "Epoch 10/20\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 4.8553INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.8053 - val_loss: 4.3738\n",
      "Epoch 11/20\n",
      " 92/106 [=========================>....] - ETA: 0s - loss: 4.8494INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_5_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.7776 - val_loss: 4.3198\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7443 - val_loss: 4.3636\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 4.7372 - val_loss: 4.3616\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 4.7428 - val_loss: 4.3917\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7403 - val_loss: 4.4210\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7215 - val_loss: 4.5370\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6997 - val_loss: 5.1380\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7463 - val_loss: 4.9646\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 4.7447 - val_loss: 4.6079\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6963 - val_loss: 4.4272\n"
     ]
    }
   ],
   "source": [
    "model_5 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(563,), dtype=tf.float32),\n",
    "    layers.Dense(512, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_5_one_hot\")\n",
    "\n",
    "model_5.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_5_history = model_5.fit(train_dataset_2,\n",
    "                              validation_data=val_dataset_2,\n",
    "                              epochs=20,\n",
    "                              callbacks=[tensorboard(model_5.name),\n",
    "                                         checkpoint(model_5.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c710b72-c1c3-402f-9d16-2da2ea005378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8090 (pid 32896), started 0:36:07 ago. (Use '!kill 32896' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-62fb0e4ccb37bc5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-62fb0e4ccb37bc5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8090;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir model_logs/greener_manufacturing --port 8090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d8c1b53-aec1-484a-bed9-4592892c7a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5351702184135251"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_train_preds = model_5.predict(train_dataset_2)\n",
    "model_5_train_r2 = r2_score(train_target, tf.squeeze(model_5_train_preds))\n",
    "model_5_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5b9c2141-8e38-47a8-9fb6-1c41f8487b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6579319246537416"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = model_5.predict(val_dataset_2)\n",
    "model_5_r2 = r2_score(val_target, tf.squeeze(model_5_preds))\n",
    "model_5_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c389836e-17fc-4228-b7be-720bc3f8bf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6537673556087245"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_loaded = tf.keras.models.load_model(CHECKPOINT_PATH + \"/\" + model_5.name)\n",
    "model_5_loaded_preds = model_5_loaded.predict(val_dataset_2)\n",
    "model_5_loaded_r2 = r2_score(val_target, tf.squeeze(model_5_loaded_preds))\n",
    "model_5_loaded_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cfc8351a-dffe-4a06-a8a4-904183947d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49641623682750535"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_loaded_train_preds = model_5_loaded.predict(train_dataset_2)\n",
    "model_5_loaded_train_r2 = r2_score(train_target, tf.squeeze(model_5_loaded_train_preds))\n",
    "model_5_loaded_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "96bba114-a387-44e9-a7bd-3cf354921041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "101/106 [===========================>..] - ETA: 0s - loss: 76.8582INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 76.2270 - val_loss: 59.9536\n",
      "Epoch 2/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 51.4919INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 50.6719 - val_loss: 37.2696\n",
      "Epoch 3/30\n",
      " 85/106 [=======================>......] - ETA: 0s - loss: 30.6249INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 28.5849 - val_loss: 16.3016\n",
      "Epoch 4/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 12.7349INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 12.5436 - val_loss: 9.6110\n",
      "Epoch 5/30\n",
      "101/106 [===========================>..] - ETA: 0s - loss: 10.2900INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 10.2520 - val_loss: 9.4956\n",
      "Epoch 6/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1399 - val_loss: 9.4971\n",
      "Epoch 7/30\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 9.6083INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.4965 - val_loss: 7.0397\n",
      "Epoch 8/30\n",
      "104/106 [============================>.] - ETA: 0s - loss: 7.0192INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.0046 - val_loss: 4.9064\n",
      "Epoch 9/30\n",
      "104/106 [============================>.] - ETA: 0s - loss: 5.5402INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 5.5296 - val_loss: 4.4882\n",
      "Epoch 10/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 5.1513 - val_loss: 4.5004\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 5.0262 - val_loss: 4.5156\n",
      "Epoch 12/30\n",
      " 90/106 [========================>.....] - ETA: 0s - loss: 4.9869INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 4.9507 - val_loss: 4.4832\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.8954 - val_loss: 4.5379\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 4.8474 - val_loss: 4.5620\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 4.8036 - val_loss: 4.5248\n",
      "Epoch 16/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7734 - val_loss: 4.6290\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7434 - val_loss: 4.6724\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7255 - val_loss: 4.7787\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7082 - val_loss: 4.7504\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 4.6740 - val_loss: 4.8910\n",
      "Epoch 21/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 4.6627 - val_loss: 4.8647\n",
      "Epoch 22/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6604 - val_loss: 4.9604\n",
      "Epoch 23/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6462 - val_loss: 4.9476\n",
      "Epoch 24/30\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 4.6515 - val_loss: 4.8648\n",
      "Epoch 25/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6500 - val_loss: 4.6834\n",
      "Epoch 26/30\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 4.7678INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 4.7123 - val_loss: 4.4608\n",
      "Epoch 27/30\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 4.8130INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_6_one_hot\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 4.7537 - val_loss: 4.3990\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.7909 - val_loss: 4.4180\n",
      "Epoch 29/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 4.7487 - val_loss: 4.5034\n",
      "Epoch 30/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 4.6880 - val_loss: 4.6646\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(563,), dtype=tf.float32),\n",
    "    layers.Dense(198, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_6_one_hot\")\n",
    "\n",
    "model_6.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_6_history = model_6.fit(train_dataset_2,\n",
    "                              validation_data=val_dataset_2,\n",
    "                              epochs=30,\n",
    "                              callbacks=[tensorboard(model_6.name),\n",
    "                                         checkpoint(model_6.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab167236-c3fa-46b0-b1a1-50a213650ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565138307115874"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_train_preds = model_6.predict(train_dataset_2)\n",
    "model_6_train_r2 = r2_score(train_target, tf.squeeze(model_6_train_preds))\n",
    "model_6_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "68bb9a07-edc5-418f-8c52-11ccb1031a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6602734619347431"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_preds = model_6.predict(val_dataset_2)\n",
    "model_6_r2 = r2_score(val_target, tf.squeeze(model_6_preds))\n",
    "model_6_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d9aa3791-7400-49f5-9680-e9b1d4021c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 97/106 [==========================>...] - ETA: 0s - loss: 86.0750INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 85.5173 - val_loss: 76.9824\n",
      "Epoch 2/30\n",
      "106/106 [==============================] - ETA: 0s - loss: 73.3827INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 73.3827 - val_loss: 65.6088\n",
      "Epoch 3/30\n",
      "101/106 [===========================>..] - ETA: 0s - loss: 62.3618INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 62.0739 - val_loss: 54.3454\n",
      "Epoch 4/30\n",
      " 89/106 [========================>.....] - ETA: 0s - loss: 51.7713INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 50.8351 - val_loss: 43.1263\n",
      "Epoch 5/30\n",
      " 90/106 [========================>.....] - ETA: 0s - loss: 40.5625INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 2s 16ms/step - loss: 39.6290 - val_loss: 31.9312\n",
      "Epoch 6/30\n",
      "101/106 [===========================>..] - ETA: 0s - loss: 28.7633INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 28.4832 - val_loss: 21.0750\n",
      "Epoch 7/30\n",
      " 97/106 [==========================>...] - ETA: 0s - loss: 18.6436INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 18.2344 - val_loss: 11.9412\n",
      "Epoch 8/30\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 11.8223INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 11.7222 - val_loss: 9.8139\n",
      "Epoch 9/30\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 10.5926INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.5240 - val_loss: 9.5369\n",
      "Epoch 10/30\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 10.2955INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 10.2455 - val_loss: 9.4987\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1659 - val_loss: 9.5185\n",
      "Epoch 12/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1509 - val_loss: 9.5310\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1492 - val_loss: 9.5357\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1489 - val_loss: 9.5381\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1490 - val_loss: 9.5397\n",
      "Epoch 16/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1491 - val_loss: 9.5399\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1493 - val_loss: 9.5400\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.1494 - val_loss: 9.5393\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1495 - val_loss: 9.5393\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 10.1495 - val_loss: 9.5386\n",
      "Epoch 21/30\n",
      " 88/106 [=======================>......] - ETA: 0s - loss: 9.9469INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 9.6780 - val_loss: 7.0700\n",
      "Epoch 22/30\n",
      " 95/106 [=========================>....] - ETA: 0s - loss: 7.0687INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 6.9286 - val_loss: 4.9576\n",
      "Epoch 23/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 5.7829INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.7285 - val_loss: 4.6767\n",
      "Epoch 24/30\n",
      "100/106 [===========================>..] - ETA: 0s - loss: 5.3158INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 5.2623 - val_loss: 4.5467\n",
      "Epoch 25/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 5.1638INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.1248 - val_loss: 4.4936\n",
      "Epoch 26/30\n",
      "105/106 [============================>.] - ETA: 0s - loss: 5.0768INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.0783 - val_loss: 4.4458\n",
      "Epoch 27/30\n",
      " 93/106 [=========================>....] - ETA: 0s - loss: 5.0714INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 5.0244 - val_loss: 4.4344\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 5.0550 - val_loss: 4.5594\n",
      "Epoch 29/30\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 5.0124 - val_loss: 4.6455\n",
      "Epoch 30/30\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 5.0536INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_7\\assets\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 5.0081 - val_loss: 4.4120\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_7 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(376,), dtype=tf.float32),\n",
    "    layers.Dense(216, activation=\"tanh\"),\n",
    "    layers.Dense(104, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_7\")\n",
    "\n",
    "model_7.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model_7_history = model_7.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=30,\n",
    "                              callbacks=[tensorboard(model_7.name),\n",
    "                                         checkpoint(model_7.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "25f531da-d20c-4e76-ab4a-3d00a15b3930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095615914372469"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_train_preds = model_7.predict(train_dataset_1)\n",
    "model_7_train_r2 = r2_score(train_target, tf.squeeze(model_7_train_preds))\n",
    "model_7_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7b129ce1-5180-4c2a-b692-9005d7353580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667660046923078"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = model_7.predict(val_dataset_1)\n",
    "model_7_r2 = r2_score(val_target, tf.squeeze(model_7_preds))\n",
    "model_7_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9dd9219f-ab5a-429c-b156-3c93454d3824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095615914372469"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_loaded = tf.keras.models.load_model(CHECKPOINT_PATH + \"/\" + model_7.name)\n",
    "model_7_loaded_train_preds = model_7_loaded.predict(train_dataset_1)\n",
    "model_7_loaded_train_r2 = r2_score(train_target, tf.squeeze(model_7_loaded_train_preds))\n",
    "model_7_loaded_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4d95e4b7-4028-42a9-ba1c-c293a7483123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>5816</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>6585</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>7420</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>7805</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X2  X3  X4  X5  X6  X8  X10  ...  X375  X376  X377  X378  \\\n",
       "153    289   0   5   3   3   4  15   7   6    0  ...     0     0     1     0   \n",
       "311    624   0  14  17   6   4  14  10  21    0  ...     0     0     0     0   \n",
       "2914  5816   0   5   3   3   4  21   5  23    0  ...     0     0     1     0   \n",
       "3281  6585   0   4   3   3   4  22  10   5    0  ...     0     0     1     0   \n",
       "3718  7420   0  24  17   1   4  26   1   7    0  ...     0     0     1     0   \n",
       "3913  7805   0  22  20   6   4  27   1   7    0  ...     0     0     0     0   \n",
       "\n",
       "      X379  X380  X382  X383  X384  X385  \n",
       "153      0     0     0     0     0     0  \n",
       "311      0     0     0     0     0     0  \n",
       "2914     0     0     0     0     0     0  \n",
       "3281     0     0     0     0     0     0  \n",
       "3718     0     0     0     0     0     0  \n",
       "3913     0     0     0     0     0     0  \n",
       "\n",
       "[6 rows x 377 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data[\"X0\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f5783874-ce2e-40d4-87ef-e25d6453c911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, y, X0, X1, X2, X3, X4, X5, X6, X8, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, X21, X22, X23, X24, X26, X27, X28, X29, X30, X31, X32, X33, X34, X35, X36, X37, X38, X39, X40, X41, X42, X43, X44, X45, X46, X47, X48, X49, X50, X51, X52, X53, X54, X55, X56, X57, X58, X59, X60, X61, X62, X63, X64, X65, X66, X67, X68, X69, X70, X71, X73, X74, X75, X76, X77, X78, X79, X80, X81, X82, X83, X84, X85, X86, X87, X88, X89, X90, X91, X92, X93, X94, X95, X96, X97, X98, X99, X100, X101, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 378 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"X0\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "68ea5a09-8d11-4e10-be0a-2e8b6f5cbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_data[\"ID\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1402f82b-7287-49de-a5f7-94366c05fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_data.drop(\"ID\", axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7545522d-d8b7-4772-8044-6a2ac824e28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 376)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1fe9c1df-8c4b-4b56-b2e4-54bcc8822be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = tf.data.Dataset.from_tensor_slices(test_features).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "50b81636-3b54-4c9d-8517-92a8958d80de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35beb223-a4b5-41a8-a68a-f65a9833e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best parameters:\n",
    "num_dense_layers: 3\n",
    "num_dense_nodes: 474\n",
    "activation: relu\n",
    "dropout: 0.50\n",
    "learning_rate: 0.004547\n",
    "kernel: glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "af18659c-d3bb-4009-95aa-11c99c0153e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004547051234970231\n",
      "Epoch 1/30\n",
      "102/106 [===========================>..] - ETA: 0s - loss: 23.0901INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 3s 21ms/step - loss: 22.7684 - val_loss: 14.5259\n",
      "Epoch 2/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 13.1543INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 2s 17ms/step - loss: 13.0159 - val_loss: 12.6513\n",
      "Epoch 3/30\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 11.4801INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 2s 17ms/step - loss: 11.4105 - val_loss: 5.5755\n",
      "Epoch 4/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 11.0468 - val_loss: 5.6245\n",
      "Epoch 5/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.4487 - val_loss: 8.0749\n",
      "Epoch 6/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.7404 - val_loss: 6.4673\n",
      "Epoch 7/30\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 9.8569INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 9.8595 - val_loss: 5.1064\n",
      "Epoch 8/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.6541 - val_loss: 9.5047\n",
      "Epoch 9/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.8275 - val_loss: 6.1456\n",
      "Epoch 10/30\n",
      " 98/106 [==========================>...] - ETA: 0s - loss: 9.5068INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 2s 17ms/step - loss: 9.3915 - val_loss: 4.9287\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.2768 - val_loss: 10.1550\n",
      "Epoch 12/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.2745 - val_loss: 5.1279\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.0188 - val_loss: 6.4898\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.9284 - val_loss: 8.3374\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.0580 - val_loss: 6.0500\n",
      "Epoch 16/30\n",
      " 96/106 [==========================>...] - ETA: 0s - loss: 8.9725INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 2s 19ms/step - loss: 8.9123 - val_loss: 4.6945\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.8487 - val_loss: 4.7350\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.8092 - val_loss: 4.8852\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3474 - val_loss: 5.0288\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.5646 - val_loss: 6.7780\n",
      "Epoch 21/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5480 - val_loss: 6.9771\n",
      "Epoch 22/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.6153 - val_loss: 4.7902\n",
      "Epoch 23/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.4244 - val_loss: 5.8099\n",
      "Epoch 24/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.6697 - val_loss: 4.7753\n",
      "Epoch 25/30\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.1339 - val_loss: 5.2399\n",
      "Epoch 26/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.0096 - val_loss: 5.1988\n",
      "Epoch 27/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.0462 - val_loss: 5.0473\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7124 - val_loss: 5.3992\n",
      "Epoch 29/30\n",
      " 99/106 [===========================>..] - ETA: 0s - loss: 7.7690INFO:tensorflow:Assets written to: model_experiments/greener_manufacturing\\model_8\\assets\n",
      "106/106 [==============================] - 2s 16ms/step - loss: 7.6821 - val_loss: 4.5057\n",
      "Epoch 30/30\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 7.4968 - val_loss: 5.2006\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_8 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(376,), dtype=tf.float32),\n",
    "    layers.Rescaling(1/255.),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(474, kernel_initializer=\"glorot_uniform\", activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"model_8\")\n",
    "\n",
    "print(gp.x[4])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=gp.x[4])\n",
    "\n",
    "model_8.compile(loss=\"mae\",\n",
    "                optimizer=optimizer)\n",
    "\n",
    "model_8_history = model_8.fit(train_dataset_1,\n",
    "                              validation_data=val_dataset_1,\n",
    "                              epochs=30,\n",
    "                              callbacks=[tensorboard(model_8.name),\n",
    "                                         checkpoint(model_8.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "7cba051c-9efd-440e-9da3-2c4c9e4c9394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 5.2006\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 6.3032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.200592994689941, 6.303225040435791)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.evaluate(val_dataset_1), model_8.evaluate(train_dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0986de1e-f09c-414e-b932-78d58e523d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step - loss: 4.5057\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 5.7525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.505660533905029, 5.752542972564697)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_loaded = tf.keras.models.load_model(CHECKPOINT_PATH + \"/\" + model_8.name)\n",
    "model_8_loaded.evaluate(val_dataset_1), model_8_loaded.evaluate(train_dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5bda1dba-e9dd-442c-ba13-510eb48d71ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3836053152775497"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_train_preds = model_8.predict(train_dataset_1)\n",
    "model_8_train_r2 = r2_score(train_target, tf.squeeze(model_8_train_preds))\n",
    "model_8_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "97751996-6fcb-43da-b83c-c90667e750da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5673379389335982"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_preds = model_8.predict(val_dataset_1)\n",
    "model_8_r2 = r2_score(val_target, tf.squeeze(model_8_preds))\n",
    "model_8_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "72500f2c-be01-49e4-9803-5ce0a77c84c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42561689908712663"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_loaded_train_preds = model_8_loaded.predict(train_dataset_1)\n",
    "model_8_loaded_train_r2 = r2_score(train_target, tf.squeeze(model_8_loaded_train_preds))\n",
    "model_8_loaded_train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "34f1ed76-a45e-4eec-946c-d27725084c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6205107872463133"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_loaded_preds = model_8_loaded.predict(val_dataset_1)\n",
    "model_8_loaded_r2 = r2_score(val_target, tf.squeeze(model_8_loaded_preds))\n",
    "model_8_loaded_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "44db9129-625c-4b12-89ba-27128efaf6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4209,), dtype=float32, numpy=\n",
       "array([ 75.24222 ,  89.40934 ,  73.28183 , ...,  91.34294 , 104.086754,\n",
       "        90.10238 ], dtype=float32)>"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = tf.squeeze(model_4.predict(test_features))\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a6f3b965-b0c8-4d34-b7df-1030229628a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>8410</td>\n",
       "      <td>97.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>8411</td>\n",
       "      <td>89.417847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>8413</td>\n",
       "      <td>91.342941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>8414</td>\n",
       "      <td>104.086754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>8416</td>\n",
       "      <td>90.102379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID           y\n",
       "4204  8410   97.000732\n",
       "4205  8411   89.417847\n",
       "4206  8413   91.342941\n",
       "4207  8414  104.086754\n",
       "4208  8416   90.102379"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\"ID\": list(test_id),\n",
    "                        \"y\": list(test_preds.numpy())})\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "90a9bf21-a68a-4766-a1f6-b8a883310384",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"greener_manufacturing_regression_submission_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2e143-5d18-4165-9303-77927b4edb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
