{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e33bbf-f779-4d0c-a8f9-4a7e258dabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664f7dcd-cfb7-4faf-a2c6-ef087d819154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ba73b5-2c04-45d0-9409-4ea10e341b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'robonet',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_bio',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_xnli',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a825354c-38ba-4070-8dbf-2d6a3aefba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77e1041-1b0b-46dd-9aad-3568412f3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"ag_news_subset\" in tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8573c348-e97e-46a2-95df-25da2844c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data), metadata = tfds.load(\"ag_news_subset\", \n",
    "                                              with_info=True, \n",
    "                                              as_supervised=True, \n",
    "                                              split=[\"train\", \"test\"], \n",
    "                                              shuffle_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9f5b39-bd7e-4a44-87e2-c5847dac1c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World', 'Sports', 'Business', 'Sci/Tech']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5f4f8d-0372-4c55-b5cd-9d17ba62943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = metadata.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092d041c-163a-4eb1-9617-e26446721b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = metadata.splits[\"train\"].num_examples\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3de90a1-bda5-4f45-9745-69b061dfb211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c180d5f6-f3f6-47fd-bfe3-42440cf483f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'AMD #39;s new dual-core Opteron chip is designed mainly for corporate computing applications, including databases, Web services, and financial transactions.', shape=(), dtype=string) tf.Tensor(3, shape=(), dtype=int64)\n",
      "\n",
      "tf.Tensor(b'Reuters - Major League Baseball\\\\Monday announced a decision on the appeal filed by Chicago Cubs\\\\pitcher Kerry Wood regarding a suspension stemming from an\\\\incident earlier this season.', shape=(), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n",
      "\n",
      "tf.Tensor(b'President Bush #39;s  quot;revenue-neutral quot; tax reform needs losers to balance its winners, and people claiming the federal deduction for state and local taxes may be in administration planners #39; sights, news reports say.', shape=(), dtype=string) tf.Tensor(2, shape=(), dtype=int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(3):\n",
    "    sent, label = data\n",
    "    print(sent, label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc005001-ab37-417d-ad3d-320466f23fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_sentences = []\n",
    "train_labels =  []\n",
    "for data in train_data.as_numpy_iterator():\n",
    "    sentence, label = data\n",
    "    train_sentences.append(sentence)\n",
    "    train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa30c4bc-a476-4fb4-ac2c-e38b54d89684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 120000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72444ffe-8ecc-4cdf-8e66-a4efd572dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceeaa1f4-eb03-4ed5-8087-cd31af7fa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(np.array(train_sentences), \n",
    "                                                                            np.array(train_labels),\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b53fde6-cfdb-4b85-906b-30ae09b3e3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'Oil futures prices bolted 5 percent higher yesterday, climbing above \\\\$44 a barrel after US government data showed a slight decline in crude and heating oil supplies ',\n",
       " 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0], train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d02ed351-d16f-4c0d-a20a-aa861ced2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab7b09e-eb0d-4a76-99e8-fc1b393c61da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.06790625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_length = [len(text.split()) for text in train_sentences]\n",
    "sentence_mean_length = np.mean(sentence_length)\n",
    "sentence_mean_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a592e7-fe9a-45ce-8a12-b0fc30e83ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vocab = 10000\n",
    "max_length = int(np.percentile(sentence_length, 95))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab7ddaf-c415-4e64-a268-4b7cc2af4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizor = layers.TextVectorization(max_tokens=max_vocab,\n",
    "                                           output_mode=\"int\",\n",
    "                                           output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deac5160-f942-495d-adab-9ca3493b9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizor.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a8d087-d622-4fa0-bfc8-d64c8464a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a25d3b25-ccb7-4082-b3f2-b7866aedfcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 45), dtype=int64, numpy=\n",
       "array([[   2, 1323,   75,   27,    1,    6, 2540,   26,   31,  341,    9,\n",
       "           2,  643, 1676,   10,    1,    4,    2,    1, 2211,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = random.choice(train_sentences)\n",
    "text_vectorizor([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2963faaf-8f90-4d4a-bd0d-022cf707a9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vectorizor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b74e0ac-6ba3-44c3-b4a1-6ad619374363",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_vocab = text_vectorizor.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a64566-881f-47a9-b95f-2bb1d900bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['', '[UNK]', 'the', 'a', 'to'],\n",
       " ['terminal',\n",
       "  'tenth',\n",
       "  'temperature',\n",
       "  'taxing',\n",
       "  'targetstocksquickinfofullquotegtmmcnltagt'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab[:5], words_in_vocab[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ff37363-ce1c-4ae1-8cc4-42bf2a791d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = layers.Embedding(input_dim=max_vocab,\n",
    "                                  output_dim=128,\n",
    "                                  input_length=max_length,\n",
    "                                  mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3e6cde1-923c-4738-881f-87663dd58dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 45, 128), dtype=float32, numpy=\n",
       "array([[[-0.04085212, -0.00417141,  0.02748472, ..., -0.04044526,\n",
       "          0.02812858,  0.0303327 ],\n",
       "        [ 0.02315641,  0.01602769, -0.03223325, ...,  0.01993481,\n",
       "          0.03317058,  0.02456108],\n",
       "        [ 0.02036578, -0.02145822, -0.02331859, ...,  0.00377025,\n",
       "          0.00629511, -0.02652284],\n",
       "        ...,\n",
       "        [ 0.03571234,  0.02351517,  0.01079812, ...,  0.02547474,\n",
       "          0.02602999,  0.04793067],\n",
       "        [ 0.03571234,  0.02351517,  0.01079812, ...,  0.02547474,\n",
       "          0.02602999,  0.04793067],\n",
       "        [ 0.03571234,  0.02351517,  0.01079812, ...,  0.02547474,\n",
       "          0.02602999,  0.04793067]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embedding(text_vectorizor([sample_sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4ce0f0b-5458-46fe-80c3-5cefecaab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_classification_model(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model for binary/multi-class classification.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: 1D array or list of actual values.\n",
    "    - y_preds: 1D array or list of predicted values.\n",
    "\n",
    "    Returns:\n",
    "    - evaluation_results: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_preds)\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(y_true, y_preds, average=\"weighted\")\n",
    "    return {\"acc\": acc,\n",
    "            \"pre\": pre,\n",
    "            \"rec\": rec,\n",
    "            \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521b5acc-b436-4b02-85de-11ffc78712fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences), type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9f9a85a-134d-47a5-a966-4be0f12e5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f48178c0-7228-4f49-b9aa-dbc8ae51993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cfdd4f7-3e18-470a-8717-c229853c9dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfid&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfid&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfid', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "baseline_model = Pipeline([\n",
    "    (\"tfid\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "baseline_model.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55b3b6e7-3c66-4886-b380-2692df665a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975833333333333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.score(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9851630f-d9af-4638-941f-024dbb92f277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 2, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_preds = baseline_model.predict(val_sentences)\n",
    "baseline_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f04df46-92ab-4667-a693-c97569308136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ced67bd-6d4f-408f-83fd-2da309985a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8975833333333333,\n",
       " 'pre': 0.8974104767422689,\n",
       " 'rec': 0.8975833333333333,\n",
       " 'f1': 0.8973931524495389}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_results = evaluate_classification_model(val_labels, baseline_model_preds)\n",
    "baseline_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5742f2f2-2557-46f3-be65-9e343b7becf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1509a41-951e-4aa7-8f18-03e62745fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,516\n",
      "Trainable params: 1,280,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6752cf2-672d-4f23-993b-80fc419f2f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 19s 6ms/step - loss: 0.4230 - accuracy: 0.8773 - val_loss: 0.2904 - val_accuracy: 0.9047\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 17s 6ms/step - loss: 0.2518 - accuracy: 0.9160 - val_loss: 0.2863 - val_accuracy: 0.9046\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 17s 6ms/step - loss: 0.2197 - accuracy: 0.9253 - val_loss: 0.2983 - val_accuracy: 0.9004\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 18s 6ms/step - loss: 0.2014 - accuracy: 0.9315 - val_loss: 0.3137 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 18s 6ms/step - loss: 0.1891 - accuracy: 0.9357 - val_loss: 0.3299 - val_accuracy: 0.8943\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 19s 6ms/step - loss: 0.1800 - accuracy: 0.9392 - val_loss: 0.3462 - val_accuracy: 0.8914\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 19s 6ms/step - loss: 0.1728 - accuracy: 0.9417 - val_loss: 0.3621 - val_accuracy: 0.8886\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 20s 7ms/step - loss: 0.1668 - accuracy: 0.9436 - val_loss: 0.3777 - val_accuracy: 0.8859\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 22s 7ms/step - loss: 0.1618 - accuracy: 0.9452 - val_loss: 0.3929 - val_accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 20s 7ms/step - loss: 0.1574 - accuracy: 0.9466 - val_loss: 0.4079 - val_accuracy: 0.8827\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=\"accuracy\")\n",
    "\n",
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f3c1ebd-5f3e-4347-b481-50989acc285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24000,), dtype=int64, numpy=array([2, 3, 2, ..., 2, 0, 3], dtype=int64)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = tf.argmax(model_1.predict(val_dataset), axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "210f4ad8-3c7a-45e2-9bd4-c9251f850abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24000,), dtype=int64, numpy=array([2, 3, 2, ..., 2, 0, 3], dtype=int64)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccc23d44-0fd3-456f-b4db-f1c110f77d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8826666666666667,\n",
       " 'pre': 0.8831185127830619,\n",
       " 'rec': 0.8826666666666667,\n",
       " 'f1': 0.8828313920326015}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = evaluate_classification_model(val_labels, model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43f97e81-a4b7-4c4a-bd29-442999265c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "873e39ea-8324-48d0-a5cc-89ceaf3bf9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 45, 64)            49408     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,362,692\n",
      "Trainable params: 1,362,692\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19cdf3bf-ca5f-4717-bd45-5b6cb7a7fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 88s 27ms/step - loss: 0.0873 - accuracy: 0.9699 - val_loss: 0.6860 - val_accuracy: 0.8690\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 81s 27ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.7299 - val_accuracy: 0.8640\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 84s 28ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.8483 - val_accuracy: 0.8493\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 86s 29ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.8252 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 87s 29ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.7867 - val_accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_2_history = model_2.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "505b4e44-e70c-4913-a2bd-58d16cc88678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8602916666666667,\n",
       " 'pre': 0.862262106566085,\n",
       " 'rec': 0.8602916666666667,\n",
       " 'f1': 0.8603818230153875}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.argmax(model_2.predict(val_dataset), axis=1)\n",
    "model_2_results = evaluate_classification_model(val_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b98fd53-b2cd-478a-969b-381182663235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Conv1D(10, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(10, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6efae40-dbc2-4fe8-8b7b-4df5eecd57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 43, 10)            3850      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 21, 10)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 19, 10)            310       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 9, 10)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 364       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,284,524\n",
      "Trainable params: 1,284,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b056e2e-76bf-4298-947a-6622b1ed88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 0.2068 - accuracy: 0.9251 - val_loss: 0.4228 - val_accuracy: 0.8770\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 24s 8ms/step - loss: 0.1227 - accuracy: 0.9573 - val_loss: 0.5195 - val_accuracy: 0.8702\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 25s 8ms/step - loss: 0.0859 - accuracy: 0.9720 - val_loss: 0.6483 - val_accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_3_history = model_3.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b1397a2c-540f-4556-bf24-a6136769d117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.86675,\n",
       " 'pre': 0.8681200453835706,\n",
       " 'rec': 0.86675,\n",
       " 'f1': 0.8667451424299552}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds = tf.argmax(model_3.predict(val_dataset), axis=1)\n",
    "model_3_results = evaluate_classification_model(val_labels, model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91d071cb-ad3d-4dd5-a7cf-2ffd02117e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(16, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(16))(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43de4f47-c4c2-4714-8d6e-cc1778e023b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 45, 32)           18560     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32)               6272      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,304,964\n",
      "Trainable params: 1,304,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85e418d0-7709-4753-8947-78c92730b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 158s 49ms/step - loss: 0.1344 - accuracy: 0.9553 - val_loss: 0.4798 - val_accuracy: 0.8748\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 150s 50ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 0.5820 - val_accuracy: 0.8699\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 153s 51ms/step - loss: 0.0479 - accuracy: 0.9841 - val_loss: 0.6490 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 156s 52ms/step - loss: 0.0405 - accuracy: 0.9864 - val_loss: 0.6677 - val_accuracy: 0.8714\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 162s 54ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.6976 - val_accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_4_history = model_4.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5b68a83-7fe3-4810-aaf9-83ea6dc1b83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.87, 'pre': 0.8709918534041641, 'rec': 0.87, 'f1': 0.8702165052972917}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.argmax(model_4.predict(val_dataset), axis=1)\n",
    "model_4_results = evaluate_classification_model(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "146d976e-b752-498d-ba75-c8a797f0ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.GRU(32, return_sequences=True)(x)\n",
    "x = layers.GRU(32)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f520b4e6-4703-4ed4-8a92-209bfc8f5321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 45, 32)            15552     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 32)                6336      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,302,020\n",
      "Trainable params: 1,302,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ab0f544-d49b-49dd-81f2-9e38829ad388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 105s 32ms/step - loss: 0.1235 - accuracy: 0.9562 - val_loss: 0.5647 - val_accuracy: 0.8695\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 95s 32ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.6987 - val_accuracy: 0.8680\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 95s 32ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.7471 - val_accuracy: 0.8675\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 96s 32ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.7835 - val_accuracy: 0.8670\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 93s 31ms/step - loss: 0.0314 - accuracy: 0.9895 - val_loss: 0.8344 - val_accuracy: 0.8638\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_5_history = model_5.fit(train_dataset, \n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a786f431-e3b8-4bc4-b6d1-8617c44cf717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8638333333333333,\n",
       " 'pre': 0.8649015383972944,\n",
       " 'rec': 0.8638333333333333,\n",
       " 'f1': 0.8640326728012026}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.argmax(model_5.predict(val_dataset), axis=1)\n",
    "model_5_results = evaluate_classification_model(val_labels, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "515da458-3cf9-486f-a014-c6f8ef97dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2fc6eae-1ba9-4320-a15e-9b521feb0137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52a72236-84c9-4c9c-a4a5-6419b5779976",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83a82c47-ca54-4aa3-a8fc-583d1cbffd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert False\n",
      "dropout_37 False\n",
      "classifier False\n"
     ]
    }
   ],
   "source": [
    "for layer in bert_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c00cff9-3b42-438e-9e66-e819597247e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d483be31-5c5b-499b-8c1c-8e682eb71a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.bytes_)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences), type(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba6a69e5-2706-4488-9d41-04533d53c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_list = train_sentences.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c4ed8d8-73c8-44e5-a030-3c317528d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c49e6b7-9b48-48e2-8c31-95d8e639c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_bert = bert_tokenizer(train_sentences_list, padding=True, truncation=True, return_tensors=\"tf\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0aa32b4-3155-4792-b2ee-c1241fb183b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sentences_bert = bert_tokenizer(val_sentences.astype(str).tolist(), padding=True, truncation=True, return_tensors=\"tf\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "635fab6b-164d-4680-a675-f88ba4c00745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(96000, 372), dtype=int32, numpy=\n",
       "array([[  101,  3514, 17795, ...,     0,     0,     0],\n",
       "       [  101,  2149, 13095, ...,     0,     0,     0],\n",
       "       [  101,  5522,  1006, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  7211,  1006, ...,     0,     0,     0],\n",
       "       [  101,  6950,  2012, ...,     0,     0,     0],\n",
       "       [  101,  9274,  2097, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "391a9f7e-449d-4955-bd8a-ed3156160f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_dataset = tf.data.Dataset.from_tensor_slices((train_sentences_bert, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_bert_dataset = tf.data.Dataset.from_tensor_slices((val_sentences_bert, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea63d368-1dd5-46e7-a3a4-3222d974f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 372), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bert_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "729d6491-c68d-4bad-8dbf-1da437e9f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(372,), dtype=tf.int32)\n",
    "x = bert_model(inputs)[\"logits\"]\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_bert = tf.keras.Model(inputs, outputs, name=\"model_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65e4d509-19ae-4491-b792-c6733d5e8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_bert\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 372)]             0         \n",
      "                                                                 \n",
      " tf_bert_for_sequence_classi  TFSequenceClassifierOutp  109483778\n",
      " fication (TFBertForSequence  ut(loss=None, logits=(No           \n",
      " Classification)             ne, 2),                             \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,790\n",
      "Trainable params: 12\n",
      "Non-trainable params: 109,483,778\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e37b1593-b9b4-49ec-9c3b-a2933fd5514a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  65/3000 [..............................] - ETA: 1:25:36 - loss: 1.4123 - accuracy: 0.2466"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model_bert\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m                    optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                    metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m model_bert_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_bert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_bert_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_bert_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_bert.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                   optimizer=\"adam\",\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "model_bert_history = model_bert.fit(train_bert_dataset,\n",
    "                                    validation_data=val_bert_dataset,\n",
    "                                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27e1e952-6cfc-4383-be42-2eb6ef0e31b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_percent = int(len(train_sentences) * 0.1)\n",
    "train_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4419629d-ef33-4540-b0b1-2b74a2989f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_10_percent = train_sentences[:train_10_percent]\n",
    "train_labels_10_percent = train_labels[:train_10_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60276623-e523-4218-96b6-56bdb10bfb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ba226cc-0c37-40b8-8127-80c8a7f9e319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2434\n",
       "1    2431\n",
       "2    2384\n",
       "0    2351\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_labels_10_percent).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "de51782b-ebdf-40aa-a400-1a9ae29dd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_10_percent = tf.data.Dataset.from_tensor_slices((train_sentences_10_percent, train_labels_10_percent)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2056808-9c6b-48a6-a892-0e4727588640",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(16, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(16))(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_6 = tf.keras.Model(inputs, outputs, name=\"model_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f229c0c2-2762-4437-ba7c-4dbda93715f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 45)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 45, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 45, 32)           18560     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32)               6272      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,304,964\n",
      "Trainable params: 1,304,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4f77439-f466-4d1a-bc72-b0a582f15a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10 ** (epoch/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a3d13219-b837-49b2-9ebd-618e66392bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_init_weights = model_6.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "00354a39-f32a-4e1e-8856-afc50e67ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "abff99b0-58b5-499d-8522-da166900527f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 28s 54ms/step - loss: 1.3859 - accuracy: 0.2655 - val_loss: 1.3862 - val_accuracy: 0.2612 - lr: 1.0000e-06\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 12s 42ms/step - loss: 1.3857 - accuracy: 0.2738 - val_loss: 1.3860 - val_accuracy: 0.2692 - lr: 1.1220e-06\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 13s 43ms/step - loss: 1.3854 - accuracy: 0.2837 - val_loss: 1.3857 - val_accuracy: 0.2788 - lr: 1.2589e-06\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 14s 45ms/step - loss: 1.3851 - accuracy: 0.2947 - val_loss: 1.3854 - val_accuracy: 0.2883 - lr: 1.4125e-06\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 13s 45ms/step - loss: 1.3848 - accuracy: 0.3069 - val_loss: 1.3851 - val_accuracy: 0.2992 - lr: 1.5849e-06\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 14s 46ms/step - loss: 1.3844 - accuracy: 0.3215 - val_loss: 1.3848 - val_accuracy: 0.3113 - lr: 1.7783e-06\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 14s 47ms/step - loss: 1.3840 - accuracy: 0.3393 - val_loss: 1.3844 - val_accuracy: 0.3271 - lr: 1.9953e-06\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3835 - accuracy: 0.3590 - val_loss: 1.3839 - val_accuracy: 0.3421 - lr: 2.2387e-06\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 1.3830 - accuracy: 0.3809 - val_loss: 1.3834 - val_accuracy: 0.3600 - lr: 2.5119e-06\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3823 - accuracy: 0.3999 - val_loss: 1.3827 - val_accuracy: 0.3783 - lr: 2.8184e-06\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3815 - accuracy: 0.4228 - val_loss: 1.3819 - val_accuracy: 0.4004 - lr: 3.1623e-06\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.3805 - accuracy: 0.4497 - val_loss: 1.3810 - val_accuracy: 0.4233 - lr: 3.5481e-06\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3793 - accuracy: 0.4733 - val_loss: 1.3798 - val_accuracy: 0.4483 - lr: 3.9811e-06\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 1.3778 - accuracy: 0.5000 - val_loss: 1.3782 - val_accuracy: 0.4783 - lr: 4.4668e-06\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.3758 - accuracy: 0.5239 - val_loss: 1.3761 - val_accuracy: 0.5088 - lr: 5.0119e-06\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.3730 - accuracy: 0.5489 - val_loss: 1.3731 - val_accuracy: 0.5250 - lr: 5.6234e-06\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.3690 - accuracy: 0.5726 - val_loss: 1.3687 - val_accuracy: 0.5446 - lr: 6.3096e-06\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3629 - accuracy: 0.5890 - val_loss: 1.3615 - val_accuracy: 0.5625 - lr: 7.0795e-06\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.3524 - accuracy: 0.5925 - val_loss: 1.3486 - val_accuracy: 0.5663 - lr: 7.9433e-06\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.3325 - accuracy: 0.5815 - val_loss: 1.3220 - val_accuracy: 0.5462 - lr: 8.9125e-06\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 1.2889 - accuracy: 0.5517 - val_loss: 1.2618 - val_accuracy: 0.5133 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.1993 - accuracy: 0.5115 - val_loss: 1.1532 - val_accuracy: 0.4938 - lr: 1.1220e-05\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 1.0809 - accuracy: 0.4992 - val_loss: 1.0464 - val_accuracy: 0.4971 - lr: 1.2589e-05\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.9840 - accuracy: 0.5111 - val_loss: 0.9719 - val_accuracy: 0.5208 - lr: 1.4125e-05\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 0.9065 - accuracy: 0.5494 - val_loss: 0.9069 - val_accuracy: 0.5713 - lr: 1.5849e-05\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 0.8256 - accuracy: 0.6524 - val_loss: 0.8320 - val_accuracy: 0.6779 - lr: 1.7783e-05\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 0.7305 - accuracy: 0.7748 - val_loss: 0.7460 - val_accuracy: 0.7617 - lr: 1.9953e-05\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.6258 - accuracy: 0.8458 - val_loss: 0.6639 - val_accuracy: 0.7983 - lr: 2.2387e-05\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.5230 - accuracy: 0.8777 - val_loss: 0.5965 - val_accuracy: 0.8121 - lr: 2.5119e-05\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.4335 - accuracy: 0.9016 - val_loss: 0.5515 - val_accuracy: 0.8171 - lr: 2.8184e-05\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.3604 - accuracy: 0.9211 - val_loss: 0.5289 - val_accuracy: 0.8217 - lr: 3.1623e-05\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.3017 - accuracy: 0.9352 - val_loss: 0.5141 - val_accuracy: 0.8275 - lr: 3.5481e-05\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.2549 - accuracy: 0.9459 - val_loss: 0.5169 - val_accuracy: 0.8275 - lr: 3.9811e-05\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.2191 - accuracy: 0.9548 - val_loss: 0.5094 - val_accuracy: 0.8338 - lr: 4.4668e-05\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.1881 - accuracy: 0.9617 - val_loss: 0.5425 - val_accuracy: 0.8183 - lr: 5.0119e-05\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.1616 - accuracy: 0.9682 - val_loss: 0.5837 - val_accuracy: 0.8108 - lr: 5.6234e-05\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.1367 - accuracy: 0.9744 - val_loss: 0.6159 - val_accuracy: 0.8062 - lr: 6.3096e-05\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.1179 - accuracy: 0.9781 - val_loss: 0.6264 - val_accuracy: 0.8087 - lr: 7.0795e-05\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.1008 - accuracy: 0.9822 - val_loss: 0.6201 - val_accuracy: 0.8200 - lr: 7.9433e-05\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0850 - accuracy: 0.9860 - val_loss: 0.7287 - val_accuracy: 0.7904 - lr: 8.9125e-05\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0815 - accuracy: 0.9853 - val_loss: 0.7275 - val_accuracy: 0.7958 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0782 - accuracy: 0.9846 - val_loss: 0.6871 - val_accuracy: 0.8129 - lr: 1.1220e-04\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0724 - accuracy: 0.9846 - val_loss: 0.7056 - val_accuracy: 0.8142 - lr: 1.2589e-04\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0632 - accuracy: 0.9881 - val_loss: 0.7345 - val_accuracy: 0.8158 - lr: 1.4125e-04\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0531 - accuracy: 0.9908 - val_loss: 0.7738 - val_accuracy: 0.8121 - lr: 1.5849e-04\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0522 - accuracy: 0.9904 - val_loss: 0.8151 - val_accuracy: 0.8096 - lr: 1.7783e-04\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.8191 - val_accuracy: 0.8054 - lr: 1.9953e-04\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0570 - accuracy: 0.9874 - val_loss: 0.8841 - val_accuracy: 0.8046 - lr: 2.2387e-04\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0749 - accuracy: 0.9807 - val_loss: 0.8705 - val_accuracy: 0.7979 - lr: 2.5119e-04\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0874 - accuracy: 0.9756 - val_loss: 0.7526 - val_accuracy: 0.8054 - lr: 2.8184e-04\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0550 - accuracy: 0.9861 - val_loss: 0.8497 - val_accuracy: 0.8021 - lr: 3.1623e-04\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0463 - accuracy: 0.9887 - val_loss: 0.8644 - val_accuracy: 0.8075 - lr: 3.5481e-04\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0756 - accuracy: 0.9804 - val_loss: 0.7995 - val_accuracy: 0.8138 - lr: 3.9811e-04\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0548 - accuracy: 0.9864 - val_loss: 0.8311 - val_accuracy: 0.8142 - lr: 4.4668e-04\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 15s 52ms/step - loss: 0.0396 - accuracy: 0.9906 - val_loss: 0.8362 - val_accuracy: 0.8150 - lr: 5.0119e-04\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0377 - accuracy: 0.9916 - val_loss: 0.9302 - val_accuracy: 0.8025 - lr: 5.6234e-04\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0579 - accuracy: 0.9857 - val_loss: 0.8515 - val_accuracy: 0.8067 - lr: 6.3096e-04\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.8585 - val_accuracy: 0.8058 - lr: 7.0795e-04\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 15s 52ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.8145 - val_accuracy: 0.8138 - lr: 7.9433e-04\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0288 - accuracy: 0.9930 - val_loss: 0.8812 - val_accuracy: 0.8158 - lr: 8.9125e-04\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.9087 - val_accuracy: 0.8050 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0622 - accuracy: 0.9809 - val_loss: 0.7345 - val_accuracy: 0.8292 - lr: 0.0011\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.7878 - val_accuracy: 0.8338 - lr: 0.0013\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.8720 - val_accuracy: 0.8288 - lr: 0.0014\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.8109 - val_accuracy: 0.8375 - lr: 0.0016\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0383 - accuracy: 0.9871 - val_loss: 0.8723 - val_accuracy: 0.8271 - lr: 0.0018\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0552 - accuracy: 0.9816 - val_loss: 0.8459 - val_accuracy: 0.8079 - lr: 0.0020\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.8098 - val_accuracy: 0.8271 - lr: 0.0022\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.8232 - val_accuracy: 0.8271 - lr: 0.0025\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.7526 - val_accuracy: 0.8375 - lr: 0.0028\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 15s 52ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.7863 - val_accuracy: 0.8296 - lr: 0.0032\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.7954 - val_accuracy: 0.8225 - lr: 0.0035\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.8585 - val_accuracy: 0.8000 - lr: 0.0040\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.7488 - val_accuracy: 0.8388 - lr: 0.0045\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.7968 - val_accuracy: 0.8392 - lr: 0.0050\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 0.0362 - accuracy: 0.9871 - val_loss: 0.7924 - val_accuracy: 0.8321 - lr: 0.0056\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.8125 - val_accuracy: 0.8350 - lr: 0.0063\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 1.0349 - val_accuracy: 0.8163 - lr: 0.0071\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 15s 52ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.8077 - val_accuracy: 0.8167 - lr: 0.0079\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.8754 - val_accuracy: 0.8292 - lr: 0.0089\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.7959 - val_accuracy: 0.8367 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.9162 - val_accuracy: 0.8179 - lr: 0.0112\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0602 - accuracy: 0.9812 - val_loss: 0.6968 - val_accuracy: 0.8338 - lr: 0.0126\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 15s 52ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.8173 - val_accuracy: 0.8217 - lr: 0.0141\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.8731 - val_accuracy: 0.8171 - lr: 0.0158\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.0947 - accuracy: 0.9675 - val_loss: 0.8582 - val_accuracy: 0.8108 - lr: 0.0178\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.1548 - accuracy: 0.9485 - val_loss: 0.8166 - val_accuracy: 0.7954 - lr: 0.0200\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.1917 - accuracy: 0.9312 - val_loss: 0.7186 - val_accuracy: 0.7871 - lr: 0.0224\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.2081 - accuracy: 0.9265 - val_loss: 0.7251 - val_accuracy: 0.8037 - lr: 0.0251\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.2394 - accuracy: 0.9181 - val_loss: 0.7582 - val_accuracy: 0.7812 - lr: 0.0282\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 16s 52ms/step - loss: 0.2782 - accuracy: 0.9041 - val_loss: 0.7337 - val_accuracy: 0.7892 - lr: 0.0316\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 0.3441 - accuracy: 0.8799 - val_loss: 0.6738 - val_accuracy: 0.7837 - lr: 0.0355\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.4031 - accuracy: 0.8561 - val_loss: 0.7321 - val_accuracy: 0.7596 - lr: 0.0398\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.4580 - accuracy: 0.8343 - val_loss: 0.7328 - val_accuracy: 0.7417 - lr: 0.0447\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.5280 - accuracy: 0.8069 - val_loss: 0.7696 - val_accuracy: 0.7154 - lr: 0.0501\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 0.5587 - accuracy: 0.7958 - val_loss: 0.7611 - val_accuracy: 0.7283 - lr: 0.0562\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.7101 - accuracy: 0.7352 - val_loss: 0.9518 - val_accuracy: 0.6471 - lr: 0.0631\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 15s 51ms/step - loss: 0.8306 - accuracy: 0.6849 - val_loss: 0.8922 - val_accuracy: 0.6658 - lr: 0.0708\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 16s 53ms/step - loss: 0.7726 - accuracy: 0.7058 - val_loss: 0.8862 - val_accuracy: 0.6667 - lr: 0.0794\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 18s 60ms/step - loss: 0.7655 - accuracy: 0.7042 - val_loss: 0.8940 - val_accuracy: 0.6687 - lr: 0.0891\n"
     ]
    }
   ],
   "source": [
    "model_6_history = model_6.fit(train_dataset_10_percent,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(len(val_dataset) * 0.1),\n",
    "                              epochs=100,\n",
    "                              callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "38b06a8a-2b60-4d43-8a09-0e1a9f6a0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4749bbe7-de0f-4a52-9e70-9cbddf8685ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e6fe82edc0>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-6 * 10 ** (tf.range(100)/20)\n",
    "plt.semilogx(lrs, model_6_history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e3bff57-0df6-4b53-a051-35d6eff837d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.set_weights(model_6_init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "63ac5a98-678a-42b9-a5d9-9793ba657f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.00002),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc48c49b-4913-43c1-8217-ed930cc86e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd36927-95cc-4956-b08b-7f7b6bc27d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model_name):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(monitor=\"val_loss\", \n",
    "                                              filepath=os.path.join(\"h5_models/ag_news/\", model_name + \".h5\"), \n",
    "                                              save_best_only=True)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", restore_best_weights=True, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "210e956f-c89e-408e-8b6c-bf941e1ae89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2999/3000 [============================>.] - ETA: 0s - loss: 1.0875 - accuracy: 0.5707"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x000001E688E6F370>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_6_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\saving\\hdf5_format.py:988\u001b[0m, in \u001b[0;36m_legacy_weights\u001b[1;34m(layer)\u001b[0m\n\u001b[0;32m    986\u001b[0m weights \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mnon_trainable_weights\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, tf\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights):\n\u001b[1;32m--> 988\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSave or restore weights that is not an instance of `tf.Variable` is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    990\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot supported in h5, use `save_format=\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m` instead. Received a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    991\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel or layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<keras.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x000001E688E6F370>]"
     ]
    }
   ],
   "source": [
    "model_6_history = model_6.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(len(val_dataset) * 0.1),\n",
    "                              epochs=100,\n",
    "                              callbacks=[early_stopping, checkpoint(model_6.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf3c8-b64b-4128-8cc1-bd8079ff9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546278c-3fcb-457b-ae07-c2d7af06ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d64bc4-21b8-48bd-a02f-c13fddc11624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6_preds = tf.argmax(model_6.predict(val_dataset), axis=1)\n",
    "model_6_results = evaluate_classification_model(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e76274e0-e365-42db-8171-b617908f2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 189s 58ms/step - loss: 0.1645 - accuracy: 0.9489 - val_loss: 0.3356 - val_accuracy: 0.8954 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 159s 53ms/step - loss: 0.1195 - accuracy: 0.9626 - val_loss: 0.4249 - val_accuracy: 0.8792 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 163s 54ms/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.4551 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9751\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3000/3000 [==============================] - 169s 56ms/step - loss: 0.0754 - accuracy: 0.9751 - val_loss: 0.5010 - val_accuracy: 0.8788 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 158s 53ms/step - loss: 0.1114 - accuracy: 0.9606 - val_loss: 0.4020 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 171s 57ms/step - loss: 0.0837 - accuracy: 0.9704 - val_loss: 0.4284 - val_accuracy: 0.8996 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_7 = tf.keras.Model(inputs, outputs, name=\"model_7\")\n",
    "\n",
    "model_7.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_7_history = model_7.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(len(val_dataset) * 0.1),\n",
    "                              epochs=100,\n",
    "                              callbacks=[early_stopping, \n",
    "                                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                patience=3, \n",
    "                                                factor=0.1, \n",
    "                                                min_lr=1e-7,\n",
    "                                                verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "457bc41a-405c-4e75-a0d4-3a46982c3698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8855416666666667,\n",
       " 'pre': 0.8854341318868264,\n",
       " 'rec': 0.8855416666666667,\n",
       " 'f1': 0.8854287662242164}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = tf.argmax(model_7.predict(val_dataset), axis=1)\n",
    "model_7_results = evaluate_classification_model(val_labels, model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13b8eecd-18bb-4ecb-8007-f19f76c01f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 66s 22ms/step - loss: 0.2107 - accuracy: 0.9316\n",
      "750/750 [==============================] - 16s 21ms/step - loss: 0.3758 - accuracy: 0.8855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.21071183681488037, 0.9315937757492065],\n",
       " [0.37576863169670105, 0.8855416774749756])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.evaluate(train_dataset), model_7.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59c67bb6-8ce7-4606-8dc6-54c059cabb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 51s 16ms/step - loss: 0.2198 - accuracy: 0.9305 - val_loss: 0.2839 - val_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 48s 16ms/step - loss: 0.1605 - accuracy: 0.9482 - val_loss: 0.3207 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 57s 19ms/step - loss: 0.1304 - accuracy: 0.9575 - val_loss: 0.3795 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "2998/3000 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.9641\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3000/3000 [==============================] - 58s 19ms/step - loss: 0.1074 - accuracy: 0.9641 - val_loss: 0.3970 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 52s 17ms/step - loss: 0.1215 - accuracy: 0.9570 - val_loss: 0.3755 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 52s 17ms/step - loss: 0.0959 - accuracy: 0.9659 - val_loss: 0.3913 - val_accuracy: 0.8975 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.LSTM(60, return_sequences=True)(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(50, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_8 = tf.keras.Model(inputs, outputs, name=\"model_8\")\n",
    "\n",
    "model_8.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_8_history = model_8.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(len(val_dataset) * 0.1),\n",
    "                              epochs=100,\n",
    "                              callbacks=[early_stopping, \n",
    "                                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                patience=3, \n",
    "                                                factor=0.1, \n",
    "                                                min_lr=1e-7,\n",
    "                                                verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89415ef7-3f61-4db2-96e8-1c6070f8bddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8917083333333333,\n",
       " 'pre': 0.8920033444327241,\n",
       " 'rec': 0.8917083333333333,\n",
       " 'f1': 0.8918156206195266}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8_preds = tf.argmax(model_8.predict(val_dataset), axis=1)\n",
    "model_8_results = evaluate_classification_model(val_labels, model_8_preds)\n",
    "model_8_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b042678-7cf4-48e2-8517-fbcc908c9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 20s 7ms/step - loss: 0.1899 - accuracy: 0.9350\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.3181 - accuracy: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.18987779319286346, 0.9350208044052124],\n",
       " [0.31814897060394287, 0.8917083144187927])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.evaluate(train_dataset), model_8.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c127085-3ac5-44ed-b09a-3736e21f9eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.3))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128, dropout=0.3))(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = tf.keras.activations.swish(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = tf.keras.activations.swish(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = tf.keras.activations.swish(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_9 = tf.keras.Model(inputs, outputs, name=\"model_9\")\n",
    "\n",
    "model_9.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"rmsprop\",\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_9_history = model_9.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              validation_steps=int(len(val_dataset) * 0.1),\n",
    "                              epochs=100,\n",
    "                              callbacks=[early_stopping, \n",
    "                                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                patience=3, \n",
    "                                                factor=0.1, \n",
    "                                                min_lr=1e-7,\n",
    "                                                verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d7eb2-3284-4ee9-87fd-4a882e3b4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9_preds = tf.argmax(model_9.predict(val_dataset), axis=1)\n",
    "model_9_results = evaluate_classification_model(val_labels, model_9_preds)\n",
    "model_9_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52074aee-225a-4623-a8f6-836eac110700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9.evaluate(train_dataset), model_9.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e38cb63e-14e2-47e6-8beb-daa119b0cf95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 26s 8ms/step - loss: 0.7923 - accuracy: 0.6250 - val_loss: 0.5836 - val_accuracy: 0.7079 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 25s 8ms/step - loss: 0.5930 - accuracy: 0.7091 - val_loss: 0.4937 - val_accuracy: 0.8037 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 0.4747 - accuracy: 0.8284 - val_loss: 0.3733 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 27s 9ms/step - loss: 0.3896 - accuracy: 0.8720 - val_loss: 0.3387 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 0.3460 - accuracy: 0.8892 - val_loss: 0.3154 - val_accuracy: 0.8938 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 0.3187 - accuracy: 0.8967 - val_loss: 0.3146 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 27s 9ms/step - loss: 0.2969 - accuracy: 0.9042 - val_loss: 0.3121 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 28s 9ms/step - loss: 0.2841 - accuracy: 0.9088 - val_loss: 0.3236 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 27s 9ms/step - loss: 0.2687 - accuracy: 0.9130 - val_loss: 0.3243 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2999/3000 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9168\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 0.2555 - accuracy: 0.9168 - val_loss: 0.3292 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 0.2251 - accuracy: 0.9269 - val_loss: 0.3364 - val_accuracy: 0.8933 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 26s 9ms/step - loss: 0.2191 - accuracy: 0.9285 - val_loss: 0.3382 - val_accuracy: 0.8938 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_10 = tf.keras.Model(inputs, outputs, name=\"model_10\")\n",
    "\n",
    "model_10.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_10_history = model_10.fit(train_dataset,\n",
    "                                validation_data=val_dataset,\n",
    "                                validation_steps=int(len(val_dataset) * 0.1),\n",
    "                                epochs=50,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                                                patience=3, \n",
    "                                                                                factor=0.1, \n",
    "                                                                                min_lr=1e-7,\n",
    "                                                                                verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8c75f85-8a68-47d2-b182-a37a6052ed6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.886875,\n",
       " 'pre': 0.8894414561118226,\n",
       " 'rec': 0.886875,\n",
       " 'f1': 0.886371917616612}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10_preds = tf.argmax(model_10.predict(val_dataset), axis=1)\n",
    "model_10_results = evaluate_classification_model(val_labels, model_10_preds)\n",
    "model_10_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "031497cf-06d3-46a0-bf2f-ded1f09368e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 15s 5ms/step - loss: 0.2309 - accuracy: 0.9215\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.3305 - accuracy: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.23085449635982513, 0.921500027179718],\n",
       " [0.3304807245731354, 0.8868749737739563])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.evaluate(train_dataset), model_10.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdbaabb5-8428-47f4-949d-fda1a9233c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  61/3000 [..............................] - ETA: 14:30 - loss: 1.2374 - accuracy: 0.4472"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m model_11 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs, outputs, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_11\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m model_11\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m                  optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m     15\u001b[0m                  metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m model_11_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mldl\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizor(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Conv1D(16, 3, activation=\"relu\", padding=\"causal\")(x)\n",
    "x = layers.Bidirectional(layers.LSTM(16, activation=\"relu\"))(x)\n",
    "x = layers.Dense(16)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "\n",
    "model_11 = tf.keras.Model(inputs, outputs, name=\"model_11\")\n",
    "\n",
    "model_11.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "model_11_history = model_11.fit(train_dataset,\n",
    "                                validation_data=val_dataset,\n",
    "                                validation_steps=int(len(val_dataset) * 0.1),\n",
    "                                epochs=150,\n",
    "                                callbacks=[early_stopping, \n",
    "                                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                                                patience=3, \n",
    "                                                                                factor=0.1, \n",
    "                                                                                min_lr=1e-7,\n",
    "                                                                                verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf622a41-60a3-4ff1-863e-9084bf485e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11_preds = tf.argmax(model_11.predict(val_dataset), axis=1)\n",
    "model_11_results = evaluate_classification_model(val_labels, model_11_preds)\n",
    "model_11_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0551a9e-a350-4ce8-86e7-1ad2e0133e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.evaluate(train_dataset), model_11.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d101a-edbd-4db4-b1cf-c40a879543e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
