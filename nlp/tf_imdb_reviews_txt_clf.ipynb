{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30cc9114-80cd-40b3-994e-9cc87b01c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b7d131-389d-4d2b-af0a-538d2f46a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebd0524-85f7-4c35-9987-45c645800d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178c3308-b9c9-4e42-ae01-30e8c8c2dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'robonet',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_bio',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_xnli',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list = tfds.list_builders()\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55bac9d8-5419-4c13-8903-920121c61c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"imdb_reviews\" in dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5920a34a-a6eb-4ae0-a2d6-4e31616f4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, testing_data), metadata = tfds.load(\"imdb_reviews\",\n",
    "                                                    as_supervised=True,\n",
    "                                                    shuffle_files=False,\n",
    "                                                    with_info=True,\n",
    "                                                    split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0aedcb1-b5f1-4df1-8908-79c16050a5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d42e8b0-1ac6-4794-bfc5-0f9f719a08ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74f963e-6259-45bf-af5a-0426bf140099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in training_data.take(1):\n",
    "    text, label = i\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e25655c-0bf7-4e7c-9345-52e06675c0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\", shape=(), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i in testing_data.take(1):\n",
    "    text, label = i\n",
    "    print(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72fbc7b-7390-4852-9083-6ca31a2a19f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07fbc0c-07b4-4926-b79c-d138e8c45623",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_sentences = []\n",
    "training_data_labels = []\n",
    "for data in training_data.as_numpy_iterator():\n",
    "    sentence, label = data\n",
    "    training_data_sentences.append(sentence)\n",
    "    training_data_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64091ab0-803a-4da1-8552-7f695d0a8617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_sentences), len(training_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b742bea7-50d3-4cd7-bbf7-ae3a0105bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79658db-223c-4497-88d3-7f9372d27cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(np.array(training_data_sentences),\n",
    "                                                                            np.array(training_data_labels),\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a78d51b-0e75-4a9d-b72f-4e689b4a58d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000, 20000, 5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06aeb95d-2223-4e70-bc3e-043d925de0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Zombi 3 has an interesting history in it\\'s making. Firstly, it is a sequel to Fulci\\'s hit Zombi 2, with Zombi 2 itself being of course a marketing ploy to trick people into thinking it was a sequel to George A. Romero\\'s Dawn of the Dead aka Zombi. Confusing enough? Basically, none of the films have anything to do with one another, but who cares when they make money. I guess Fulci himself starting to not care about the production about half way through Zombi 3 when he decided to walk out. Bruno Mattei was brought on board to help pad the film with additional scenes to lengthen the running time.<br /><br />Zombi 3\\'s plot is your typical zombie fare. Scientists develop a serum on an island in the Philippines, terrorists steal it unleashing a plague, and zombie run amok. The scientists want to create an antidote, while the military is set on mowing down everyone without prejudice. There are also brief inserts of a Radio DJ preaching about how we treat the planet. <br /><br />Overall, I actually liked this film. I heard horrible things, but I find the goofy dialogue quite enjoyable. The film seems to be an attempt at raising awareness about pollution, corrupted military, Man playing God, etc. I get the feeling this was at one point a serious film, but it veered off in a weird direction, presumably when Mattei came on board.<br /><br />Besides ripping off other zombie flicks, this was very reminiscent of Romero\\'s The Crazies. You hear the Radio DJ breaking the good news with, \"When you see the men in white suits & gas masks, Run to them for Help.\" This is of course played to the images of the men in white gunning down zombies. Later, they straight up steal a scene from Crazies in which one of the regular, uncontaminated people is killed by mistake.<br /><br />The gore factor is pretty good in this one with zombie hordes around every corner. How is it cool? Let me count the ways\\xc2\\x851. Zombie Birth 2. Flying Zombie Head 3. Zombie Birds. 4. Zombie with no legs swimming in a pool. My favorite zombie was the machete-wielding maniac at the gas station. He was bad ass and nearly tore down the entire building trying to kill a girl.<br /><br />Favorite Quote \\xc2\\x96 When a sergeant insists on cremating a zombie, the scientists asks, \"Don\\'t you think that once the ash is in the air, it will fall to the ground, and contaminate everything?\" To which the Sargeant boldly replies, \"Now you\\'re talking science fiction.\" He also continues to mention the \"Science Fiction\" told by the scientists even at the end when everyone dies.<br /><br />Extras: Gallery, Trailers, and Interviews, most notably the one with Mattei where he insists he directed 40% of the scenes, yet cannot recall which ones or any other significant details.<br /><br />Bottom Line: A must see for zombie and Fulci fans.<br /><br />Rating: 7/10<br /><br />Molly Celaschi www.HorrorYearbook.com MySpace.com/HorrorYearbook'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6eed769-6832-4ab3-9db1-2a213bcf7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import regex\n",
    "def keep_only_alphabet(sentence):\n",
    "    original_text = sentence.decode('utf-8', errors='ignore')\n",
    "    result_sentence = regex.sub(r'[^a-zA-Z ]', '', original_text)\n",
    "    result_sentence = re.sub(r'\\s+', ' ', result_sentence)\n",
    "    return result_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d8ab52-6a4e-43dc-9b2f-077e75487d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_only_alphabet = [keep_only_alphabet(sentence) for sentence in train_sentences]\n",
    "val_sentences_only_alphabet = [keep_only_alphabet(sentence) for sentence in val_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7451f0f5-6480-4779-80e2-a5d4c3d51f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zombi has an interesting history in its making Firstly it is a sequel to Fulcis hit Zombi with Zombi itself being of course a marketing ploy to trick people into thinking it was a sequel to George A Romeros Dawn of the Dead aka Zombi Confusing enough Basically none of the films have anything to do with one another but who cares when they make money I guess Fulci himself starting to not care about the production about half way through Zombi when he decided to walk out Bruno Mattei was brought on board to help pad the film with additional scenes to lengthen the running timebr br Zombi s plot is your typical zombie fare Scientists develop a serum on an island in the Philippines terrorists steal it unleashing a plague and zombie run amok The scientists want to create an antidote while the military is set on mowing down everyone without prejudice There are also brief inserts of a Radio DJ preaching about how we treat the planet br br Overall I actually liked this film I heard horrible things but I find the goofy dialogue quite enjoyable The film seems to be an attempt at raising awareness about pollution corrupted military Man playing God etc I get the feeling this was at one point a serious film but it veered off in a weird direction presumably when Mattei came on boardbr br Besides ripping off other zombie flicks this was very reminiscent of Romeros The Crazies You hear the Radio DJ breaking the good news with When you see the men in white suits gas masks Run to them for Help This is of course played to the images of the men in white gunning down zombies Later they straight up steal a scene from Crazies in which one of the regular uncontaminated people is killed by mistakebr br The gore factor is pretty good in this one with zombie hordes around every corner How is it cool Let me count the ways Zombie Birth Flying Zombie Head Zombie Birds Zombie with no legs swimming in a pool My favorite zombie was the machetewielding maniac at the gas station He was bad ass and nearly tore down the entire building trying to kill a girlbr br Favorite Quote When a sergeant insists on cremating a zombie the scientists asks Dont you think that once the ash is in the air it will fall to the ground and contaminate everything To which the Sargeant boldly replies Now youre talking science fiction He also continues to mention the Science Fiction told by the scientists even at the end when everyone diesbr br Extras Gallery Trailers and Interviews most notably the one with Mattei where he insists he directed of the scenes yet cannot recall which ones or any other significant detailsbr br Bottom Line A must see for zombie and Fulci fansbr br Rating br br Molly Celaschi wwwHorrorYearbookcom MySpacecomHorrorYearbook'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences_only_alphabet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee2be485-e21a-4446-b9ef-8e06a5830bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vetorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd901c59-0e5f-4792-965c-c19f01ba8ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 0\n",
    "for seq in train_sentences_only_alphabet:\n",
    "    words = seq.split()\n",
    "    if len(words) > max_length:\n",
    "        max_length = len(words)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "786ab329-451b-4206-bd7b-225811c37988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.8681"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_len = [len(sentence.split()) for sentence in train_sentences_only_alphabet]\n",
    "mean_sentence_len = np.mean(sentence_len)\n",
    "mean_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2833d6db-3fc1-4377-8134-bebd297b8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592.0499999999993"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(sentence_len, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "123b9e89-43c7-4728-be6d-caa7c6756a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = int(np.percentile(sentence_len, 95))\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c086371-5fd8-4221-9ad4-eb83139c1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences_only_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2962aa83-c22a-4308-8f91-f70a9f530fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 592), dtype=int64, numpy=\n",
       "array([[ 586,   10,   39,  916,    1,  119,   49,  916,   95,   25,  403,\n",
       "           6, 3931,   18,   11,    7,   42,  388,   10,  239, 2760,    9,\n",
       "         185,  134,    3,  516,  430,  598,    2,   62, 1551, 2357,    5,\n",
       "          11,  512,   25,    2,  650,    1, 4228,  308,   90,   79,   70,\n",
       "         356,  627,    1,    8,   11,  512,   18,  165,  308,   63, 4587,\n",
       "          46,   31,   70,   39,    2,    1,    1,   14, 6133,   13,   10,\n",
       "         254,   11,   19,   14,  777,   21,    3, 5986, 6941,  873,    3,\n",
       "           1,   31,  217,  196,  109, 1483,   17,  125,  357, 1199,    4,\n",
       "         125,  112,   15, 2296,   13,  112, 2057,   18,   22,    8,    2,\n",
       "        6971,   41,  360, 1784,  428,    5, 2563,   13,   64, 2352,   18,\n",
       "         175,   49,   24,   79,   37,   94,   39,  128,   53,    1,   13,\n",
       "         706, 3983, 2057,   56,  322,  162,  588,  157,   52, 3869,  706,\n",
       "          16,  253,  316,   21,    1,   13, 2984,    4,  402, 2057,  513,\n",
       "         584,  112,   10, 1507,   55,  637,    9,  112,    4,  169,   83,\n",
       "         713,    7, 1425,   41,    1,   13,   48,   25, 3402,    5,   50,\n",
       "         338,    4,  916, 1336,  198, 4228, 1515,   46,   48,    4,   35,\n",
       "          25,   22,   12,  266,    6, 1342,  188,   81,  610,    3, 1971,\n",
       "          33,   22, 2941,   60,   21,   11,  642,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "sample_sentence = random.choice(train_sentences_only_alphabet)\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "461a96b9-99df-4d7a-8e7b-d0400d5f5530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48a8c60e-2257-4a5e-a69f-f2b7da628c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2391623b-5011-4bf3-9dfe-6e65ff4ef74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'a', 'and']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f6950dd-a5ad-4108-9fa3-83c0ab7e97a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robs', 'rewind', 'rewatch', 'retrospect', 'restoration']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_vocab[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31ee4e0c-4b68-4602-afee-49f62c54da14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x260f87a1e50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import layers\n",
    "text_embedding = Embedding(input_dim=len(text_vectorizer.get_vocabulary()),\n",
    "                           output_dim=128,\n",
    "                           mask_zero=True)\n",
    "text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6406310f-3e9a-4cfe-b5fb-72b63cc1e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 592, 128), dtype=float32, numpy=\n",
       "array([[[-0.04520159,  0.01508335, -0.02234305, ..., -0.02887383,\n",
       "          0.00754311, -0.02291046],\n",
       "        [-0.04130728,  0.01152085, -0.04503908, ...,  0.03870931,\n",
       "          0.00176971,  0.0114314 ],\n",
       "        [-0.01618984,  0.01445836, -0.01063599, ..., -0.03516191,\n",
       "          0.03759159,  0.00547756],\n",
       "        ...,\n",
       "        [-0.02880355,  0.02532539, -0.04626453, ...,  0.02026334,\n",
       "         -0.00040517, -0.01193007],\n",
       "        [-0.02880355,  0.02532539, -0.04626453, ...,  0.02026334,\n",
       "         -0.00040517, -0.01193007],\n",
       "        [-0.02880355,  0.02532539, -0.04626453, ...,  0.02026334,\n",
       "         -0.00040517, -0.01193007]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embedding(text_vectorizer([sample_sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5f72bd1-15ff-44ef-8e60-d32acbcaa1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "def model_evaluataion_metrics(y_true, y_preds):\n",
    "    acc = accuracy_score(y_true, y_preds)\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(y_true, y_preds, average=\"weighted\")\n",
    "    return {\"acc\": acc,\n",
    "            \"pre\": pre,\n",
    "            \"rec\": rec,\n",
    "            \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dd18c71-408f-4c5f-b123-280318508946",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_only_alphabet = np.array(train_sentences_only_alphabet)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "val_sentences_only_alphabet = np.array(val_sentences_only_alphabet)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84ee7df1-3515-4dfd-b64d-d724062d2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performant dataset\n",
    "train_sentences_tensor = tf.data.Dataset.from_tensor_slices(train_sentences_only_alphabet)\n",
    "train_labels_tensor = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "train_dataset = tf.data.Dataset.zip((train_sentences_tensor, train_labels_tensor)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_sentences_tensor = tf.data.Dataset.from_tensor_slices(val_sentences_only_alphabet)\n",
    "val_labels_tensor = tf.data.Dataset.from_tensor_slices(val_labels)\n",
    "val_dataset = tf.data.Dataset.zip((val_sentences_tensor, val_labels_tensor)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64846d67-af40-434e-8fc4-a76d03c7976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 0\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0.fit(train_sentences_only_alphabet, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5702ae3-7265-4d63-9bed-78cf85bfc415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.score(val_sentences_only_alphabet, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a3e3065-3ddf-4983-b066-353854aade2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_preds = model_0.predict(val_sentences_only_alphabet)\n",
    "model_0_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8808814-ee32-441e-a2a7-56303d4be06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.863,\n",
       " 'pre': 0.8631259559351397,\n",
       " 'rec': 0.863,\n",
       " 'f1': 0.8629256359007806}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results = model_evaluataion_metrics(val_labels, model_0_preds)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54147116-e3a6-47e3-bd2d-88e227b26ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "LOGS_PATH = \"model_logs/imdb_reviews\"\n",
    "CHECKPOINT_PATH = \"model_experiments/imdb_reviews\"\n",
    "\n",
    "def tensorboard(model_name):\n",
    "    return tf.keras.callbacks.TensorBoard(os.path.join(LOGS_PATH, \n",
    "                                                       model_name, \n",
    "                                                       datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "\n",
    "def checkpoint(model_name):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_PATH, \n",
    "                                                                    model_name), \n",
    "                                              monitor=\"val_loss\", \n",
    "                                              verbose=1,\n",
    "                                              save_best_only=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                                 factor=0.1, \n",
    "                                                 patience=3, \n",
    "                                                 min_lr=1e-5)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 **(epoch/20))\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                  patience=5, \n",
    "                                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "335b4928-198a-4355-939b-e73745b6f287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 94s 138ms/step - loss: 0.1992 - accuracy: 0.9270 - val_loss: 0.3621 - val_accuracy: 0.8772\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 82s 132ms/step - loss: 0.0880 - accuracy: 0.9722 - val_loss: 0.4095 - val_accuracy: 0.8780\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 81s 130ms/step - loss: 0.0729 - accuracy: 0.9772 - val_loss: 0.4408 - val_accuracy: 0.8740\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 81s 130ms/step - loss: 0.0685 - accuracy: 0.9795 - val_loss: 0.4328 - val_accuracy: 0.8752\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 80s 129ms/step - loss: 0.0620 - accuracy: 0.9813 - val_loss: 0.4329 - val_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1\")\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                metrics=\"accuracy\")\n",
    "\n",
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a9656d4-46cb-4c0b-87fc-db603c203208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 20s 32ms/step - loss: 0.1472 - accuracy: 0.9566\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.3150 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.14720936119556427, 0.95660001039505],\n",
       " [0.31498533487319946, 0.8709999918937683])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(train_dataset), model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5036c7e-7c18-459c-ae54-d2ba41a439a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97480935],\n",
       "       [0.02142371],\n",
       "       [0.9543825 ],\n",
       "       ...,\n",
       "       [0.97795314],\n",
       "       [0.9902203 ],\n",
       "       [0.89309305]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds_probs = model_1.predict(val_sentences_only_alphabet)\n",
    "model_1_preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e93557d-fcff-4a21-b1d9-55e80ff9286e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5000,), dtype=float32, numpy=array([1., 0., 1., ..., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b24c80fe-3848-41aa-904b-9bb017c34e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.871, 'pre': 0.873373775085252, 'rec': 0.871, 'f1': 0.870966226145081}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = model_evaluataion_metrics(val_labels, model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9aef0820-1702-403f-b314-5759cbece82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 592)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 592, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                20608     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,641\n",
      "Trainable params: 1,300,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25a93a28-1972-4041-bd92-1af4c6bab398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7771\n",
      "Epoch 1: val_loss improved from inf to 0.29744, saving model to model_experiments/imdb_reviews\\model_2\n",
      "INFO:tensorflow:Assets written to: model_experiments/imdb_reviews\\model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/imdb_reviews\\model_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 16s 24ms/step - loss: 0.5084 - accuracy: 0.7771 - val_loss: 0.2974 - val_accuracy: 0.8894\n",
      "Epoch 2/50\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9079\n",
      "Epoch 2: val_loss improved from 0.29744 to 0.27488, saving model to model_experiments/imdb_reviews\\model_2\n",
      "INFO:tensorflow:Assets written to: model_experiments/imdb_reviews\\model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiments/imdb_reviews\\model_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 13s 21ms/step - loss: 0.2679 - accuracy: 0.9079 - val_loss: 0.2749 - val_accuracy: 0.8890\n",
      "Epoch 3/50\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9263\n",
      "Epoch 3: val_loss did not improve from 0.27488\n",
      "625/625 [==============================] - 12s 18ms/step - loss: 0.2146 - accuracy: 0.9262 - val_loss: 0.2872 - val_accuracy: 0.8900\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9305\n",
      "Epoch 4: val_loss did not improve from 0.27488\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.1990 - accuracy: 0.9305 - val_loss: 0.2928 - val_accuracy: 0.8892\n",
      "Epoch 5/50\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9380\n",
      "Epoch 5: val_loss did not improve from 0.27488\n",
      "625/625 [==============================] - 13s 21ms/step - loss: 0.1815 - accuracy: 0.9380 - val_loss: 0.3001 - val_accuracy: 0.8888\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9430\n",
      "Epoch 6: val_loss did not improve from 0.27488\n",
      "625/625 [==============================] - 13s 22ms/step - loss: 0.1683 - accuracy: 0.9430 - val_loss: 0.3087 - val_accuracy: 0.8884\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9450\n",
      "Epoch 7: val_loss did not improve from 0.27488\n",
      "625/625 [==============================] - 14s 22ms/step - loss: 0.1591 - accuracy: 0.9450 - val_loss: 0.3137 - val_accuracy: 0.8876\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = text_embedding(x)\n",
    "x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2\")\n",
    "\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_2_history = model_2.fit(train_dataset,\n",
    "                              validation_data=val_dataset,\n",
    "                              epochs=50,\n",
    "                              callbacks=[tensorboard(model_2.name),\n",
    "                                         checkpoint(model_2.name),\n",
    "                                         early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8c7c0bc-7c07-4e03-8d12-376203ce0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 592)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 592, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 590, 64)           24640     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 588, 64)           12352     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,319,105\n",
      "Trainable params: 1,319,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5968caf-31e0-48ef-88a5-65e251d97a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "for data in testing_data.as_numpy_iterator():\n",
    "    sentence, label = data\n",
    "    testing_sentences.append(sentence)\n",
    "    testing_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e973a885-dec7-4ded-9f9c-2fb668f85a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sentences_only_alphabet = [keep_only_alphabet(sentence) for sentence in testing_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91c97ff3-7135-43fd-a3ad-0098b32b2958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are films that make careers For George Romero it was NIGHT OF THE LIVING DEAD for Kevin Smith CLERKS for Robert Rodriguez EL MARIACHI Add to that list Onur Tukels absolutely amazing DINGALINGLESS Flawless filmmaking and as assured and as professional as any of the aforementioned movies I havent laughed this hard since I saw THE FULL MONTY And even then I dont think I laughed quite this hard So to speak Tukels talent is considerable DINGALINGLESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a linebyline examination of it to fully appreciate the uh breadth and width of it Every shot is beautifully composed a clear sign of a surehanded director and the performances all around are solid theres none of the overthetop scenery chewing one mightve expected from a film like this DINGALINGLESS is a film whose time has come'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_sentences_only_alphabet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a0f4537c-ce54-462d-9726-7561a5c91cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.87952,\n",
       " 'pre': 0.8796670459581003,\n",
       " 'rec': 0.87952,\n",
       " 'f1': 0.879508333322079}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds_probs = model_2.predict(tf.expand_dims(testing_sentences, axis=1))\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_preds_probs))\n",
    "model_2_results = model_evaluataion_metrics(testing_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4becca21-5390-4492-af20-ccb08756dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_labels[:10], model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa776fdf-4ba5-4efd-9de3-ec5578e5d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1262 - accuracy: 0.9693\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.2749 - accuracy: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.1262417584657669, 0.9692999720573425],\n",
       " [0.2748786509037018, 0.8889999985694885])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(train_dataset), model_2.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f564e7-8641-4390-94a9-e362a13b4b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
